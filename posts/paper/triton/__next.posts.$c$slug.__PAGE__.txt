1:"$Sreact.fragment"
f:I[80852,["/blog/_next/static/chunks/796e69ae18b2784c.js","/blog/_next/static/chunks/631eeae4923b8465.js"],"default"]
10:I[97367,["/blog/_next/static/chunks/ff1a16fafef87110.js","/blog/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
11:"$Sreact.suspense"
:HL["/blog/_next/static/chunks/4057cc9dbcc744c0.css","style"]
0:{"buildId":"5MI-6nhqJhNRlWoyIKnab","rsc":["$","$1","c",{"children":[["$","article",null,{"style":{"maxWidth":"800px","margin":"0 auto","padding":"20px"},"children":[["$","div",null,{"style":{"color":"#666","marginBottom":6},"children":["$","a",null,{"href":"/paper","style":{"textDecoration":"none"},"children":["/","paper"]}]}],["$","h2",null,{"style":{"marginTop":0},"children":"Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations"}],["$","div",null,{"style":{"color":"#666","marginBottom":18},"children":"2026-01-04"}],["$","p",null,{"style":{"color":"#333","fontStyle":"italic"},"children":"Structure of Triton"}],["$","hr",null,{"style":{"border":0,"borderTop":"1px solid #eee","margin":"18px 0"}}],["$","div",null,{"className":"prose","style":{"lineHeight":1.6},"children":[["$","p",null,{"children":"Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations (2019) 는 MAPL 워크숍에서 발표된 논문임.\nTriton 의 구조에 대해 다루고 있음"}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":"Triton Architecture Overview\nTriton의 아키텍처는 크게 3단계로 나뉜다."}],"\n"]}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"Triton-C (Frontend)"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"Tile Semantics: ANSI C(CUDA-C) 문법을 따르지만, int tile[16, 16]과 같이 **Tile(다차원 배열)**을 일급 객체(First-class citizen)로 취급"}],"\n",["$","li",null,{"children":"Broadcasting: NumPy와 유사한 브로드캐스팅 규칙을 언어 차원에서 지원하여 차원이 다른 텐서 간의 연산을 직관적으로 표현"}],"\n",["$","li",null,{"children":["SPMD on Blocks: CUDA와 달리 커널이 Single-threaded로 작성되지만","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"각 인스턴스가 자동으로 병렬화되어 Global Range(Grid)의 특정 타일을 처리"}],"\n",["$","li",null,{"children":"개발자는 스레드 간 동기화(Shared memory sync)를 직접 신경 쓸 필요가 없음"}],"\n"]}],"\n"]}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"Triton-IR (Middle-end)"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"LLVM-based: LLVM-IR과 구조가 유사하지만 타일 레벨의 데이터 흐름(Data-flow)과 제어 흐름(Control-flow) 분석을 위한 확장이 포함됨"}],"\n",["$","li",null,{"children":"Tile Instructions: reshape, broadcast, dot, trans 같은 타일 전용 명령어가 추가됨"}],"\n",["$","li",null,{"children":"Predication: 타일 내부의 개별 요소에 대한 분기 처리를 위해 Predicated SSA (PSSA) 형식을 사용하여 제어 흐름을 표현"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"Triton-JIT (Backend)"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"Triton-IR을 입력받아 최적화된 머신 코드(PTX/LLVM bitcode)를 생성"}],"\n",["$","li",null,{"children":"Auto-tuner가 내장되어 있어 타일 크기 등의 메타 파라미터를 자동으로 최적화"}],"\n"]}],"\n"]}],"\n"]}],"\n",["$","ol",null,{"start":"2","children":["\n",["$","li",null,{"children":"Key Compiler Optimizations\nTriton-JIT의 핵심 최적화 패스(Pass)들은 다음과 같음."}],"\n"]}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"Machine-Independent Passes"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":["Prefetching: 루프 내에서 타일 레벨 메모리 연산으로 인한 지연(Latency)을 숨기고자 함","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"컴파일러가 루프를 감지하고 적절한 프리패칭(Pre-fetching) 코드를 삽입"}],"\n",["$","li",null,{"children":"Peephole Optimization: 타일 대수(Algebra) 속성을 이용해 Trans(Trans(X)) == X와 같은 패턴을 감지하고 단순화"}],"\n"]}],"\n"]}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"Machine-Dependent Passes (GPU Targeting)"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":["Hierarchical Tiling (계층적 타일링)","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":["타일을 Micro-tile, Nano-tile로 분해하여 GPU의 메모리 계층 구조(DRAM ",["$","code",null,{"children":"->"}]," L2 ",["$","code",null,{"children":"->"}]," L1/Shared ",["$","code",null,{"children":"->"}]," Register)에 딱 맞게 매핑"]}],"\n",["$","li",null,{"children":"Polyhedral 모델 없이도 중첩된 타일링 구성을 자동으로 열거하고 최적화 가능"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["Memory Coalescing (메모리 결합)","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":["Triton-IR은 논리적으로 Single-threaded이지만","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"백엔드에서 이를 병렬화할 때 인접한 스레드가 인접한 메모리 주소에 접근하도록 스레드 순서를 재배치"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":"이를 통해 DRAM 트랜잭션 효율을 극대화"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["Shared Memory Allocation (공유 메모리 할당)","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"dot 연산처럼 연산 강도(Arithmetic Intensity)가 높은 작업의 피연산자를 Shared Memory에 저장"}],"\n",["$","li",null,{"children":"변수의 Live Range를 분석하여 선형 시간(Linear-time) 스토리지 할당 알고리즘을 사용해 최적의 위치를 결정"}],"\n"]}],"\n"]}],"\n","$L2","\n"]}],"\n"]}],"\n"]}],"\n","$L3","\n","$L4","\n","$L5","\n","$L6","\n","$L7","\n","$L8","\n","$L9"]}],"$La","$Lb"]}],["$Lc","$Ld"],"$Le"]}],"loading":null,"isPartial":false}
2:["$","li",null,{"children":["Automatic Barrier Insertion (자동 동기화)","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"RAW(Read-After-Write) 및 WAR(Write-After-Read) 해저드를 감지하기 위해 데이터 흐름 분석(Data-flow analysis)을 수행"}],"\n",["$","li",null,{"children":"필요한 지점에 자동으로 Barrier를 삽입하여 프로그램의 정확성을 보장"}],"\n"]}],"\n"]}]
3:["$","ol",null,{"start":"3","children":["\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"Performance Benchmarks"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":["Matrix Multiplication: DeepSpeech2, Transformer 등의 워크로드에서 cuBLAS와 대등한 성능을 보임","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"또한 타 DSL(Halide, TVM, PlaidML 등) 대비 최대 2-3배 빠른 성능을 기록"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["Convolutions: cuDNN의 IMPLICIT_GEMM 알고리즘을 재구현했을 때 성능 저하가 없음","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"특히 ResNet 일부 태스크에서는 cuDNN보다 뛰어난 성능을 보임"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["Shift-Convolutions: 기존에는 핸드 튜닝된 커널과 cuBLAS 호출을 섞어 써야 했던 Shift-Conv를 Triton-C로 하나의 융합된(Fused) 커널로 구현","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"Shift 연산 비용을 거의 완벽하게 숨기는 성능을 달성"}],"\n"]}],"\n"]}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"엔지니어로서의 포인트"}],"\n"]}],"\n"]}]
4:["$","ul",null,{"children":["\n",["$","li",null,{"children":["Tile Semantics & Broadcasting","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"기존의 스칼라 기반 루프 최적화(Loop transformation) 접근법 대신, Tile 자체를 타입으로 정의하고 연산 단위로 삼는 것이 하드웨어(Tensor Core 등) 활용에 얼마나 유리한지를 확인"}],"\n",["$","li",null,{"children":"Broadcasting 규칙을 IR 레벨에서 지원함으로써 차원 불일치 문제를 우아하게 해결하고 벡터화(Vectorization) 기회를 명시적으로 드러냄"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["IR Design: Predicated SSA","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"GPU와 같은 SIMT 구조를 컴파일할 때 가장 까다로운 것 중 하나가 Divergent Control Flow"}],"\n",["$","li",null,{"children":"Triton은 타일 내부의 제어 흐름을 분기(Branch)가 아닌 Predicated SSA 형식(psi 명령어 등)으로 처리"}],"\n",["$","li",null,{"children":"벡터화된 실행 흐름을 유지하면서도 조건부 연산을 효율적으로 표현"}],"\n",["$","li",null,{"children":"이는 마스킹(Masking)을 통한 벡터 연산 최적화의 핵심이자, 배울 부분"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["Automatic Synchronization","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"CUDA 프로그래밍의 가장 큰 진입 장벽인 __syncthreads() 수동 관리를 컴파일러 패스로 해결"}],"\n",["$","li",null,{"children":["**데이터 흐름 분석(Liveness Analysis)**을 통해 공유 메모리 접근 간의 의존성을 파악하고 Barrier를 자동 삽입","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"이건 고성능 병렬 컴파일러의 핵심적으로 다루어야 할 부분이라 할 수 있음"}],"\n"]}],"\n"]}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["Optimization Space Extraction","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":["Auto-tuner가 단순히 미리 정의된 템플릿을 튜닝하는 것이 아니라, IR에서 직접 최적화 공간(타일 사이즈, 계층 구조 등)을 추출하여 탐색","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"컴파일러 기반 오토튜닝의 이상적인 방향성을 보여줬다고도 할 수 있다."}],"\n"]}],"\n"]}],"\n"]}],"\n"]}],"\n"]}]
5:["$","p",null,{"children":"==============================================="}]
6:["$","p",null,{"children":"이 논문을 요약해 보자면 왜 Triton을 구현했고, 어떻게 구현했는가에 포커싱 되어 있음."}]
7:["$","ul",null,{"children":["\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"딥러닝 분야에서 새로운 아이디어를 검증하고 배포할 때, 효율적인 연산 커널(Compute Kernel)의 부재가 병목이 되는 경우가 많음"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"cuBLAS나 cuDNN 같은 벤더 라이브러리는 성능이 뛰어나지만 제한된 연산만 지원하며"}],"\n",["$","li",null,{"children":"TVM이나 PlaidML 같은 DSL은 유연하지만 벤더 라이브러리만큼의 성능을 내기 어려움\nTriton은 이러한 문제를 해결하기 위해 제안된 언어이자 컴파일러이다."}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"여기서 핵심 아이디어는 \"Tile(타일)\" 개념을 중심으로 한 프로그래밍 추상화이다."}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"Triton은 파라메트릭 타일 변수(parametric tile variables)를 사용하는 C 기반 언어(Triton-C)와 LLVM 기반의 중간 표현(Triton-IR)을 활용"}],"\n",["$","li",null,{"children":"텐서 프로그램을 효율적인 GPU 코드로 컴파일"}],"\n",["$","li",null,{"children":"결과적으로 cuBLAS와 대등한 성능을 내면서도 Shift convolution 같은 새로운 연구 아이디어를 효율적으로 구현"}],"\n"]}],"\n"]}],"\n"]}]
8:["$","p",null,{"children":"물론 장점만 있는건 아님.\n관련 내용은 아래 링크로"}]
9:["$","p",null,{"children":["$","a",null,{"href":"https://cpist.github.io/blog/posts/triton/tritonwithcuda/","children":"Link"}]}]
a:["$","hr",null,{"style":{"border":0,"borderTop":"1px solid #eee","margin":"36px 0"}}]
b:["$","$Lf",null,{}]
c:["$","link","0",{"rel":"stylesheet","href":"/blog/_next/static/chunks/4057cc9dbcc744c0.css","precedence":"next"}]
d:["$","script","script-0",{"src":"/blog/_next/static/chunks/631eeae4923b8465.js","async":true}]
e:["$","$L10",null,{"children":["$","$11",null,{"name":"Next.MetadataOutlet","children":"$@12"}]}]
12:null
