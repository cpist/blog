1:"$Sreact.fragment"
2:I[22016,["/blog/_next/static/chunks/796e69ae18b2784c.js"],""]
3:I[39756,["/blog/_next/static/chunks/ff1a16fafef87110.js","/blog/_next/static/chunks/247eb132b7f7b574.js"],"default"]
4:I[37457,["/blog/_next/static/chunks/ff1a16fafef87110.js","/blog/_next/static/chunks/247eb132b7f7b574.js"],"default"]
6:I[97367,["/blog/_next/static/chunks/ff1a16fafef87110.js","/blog/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
7:"$Sreact.suspense"
9:I[97367,["/blog/_next/static/chunks/ff1a16fafef87110.js","/blog/_next/static/chunks/247eb132b7f7b574.js"],"ViewportBoundary"]
b:I[97367,["/blog/_next/static/chunks/ff1a16fafef87110.js","/blog/_next/static/chunks/247eb132b7f7b574.js"],"MetadataBoundary"]
d:I[68027,[],"default"]
:HL["/blog/_next/static/chunks/743a8f8bdb738f7f.css","style"]
:HC["/",""]
:HL["https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css","style",{"crossOrigin":"anonymous","integrity":"sha384-n8MVd4RsNIU0KOVEMVIqhKyMVPsoloXttrTHYUjDkaWaXIhKbMCh2GbqNl2CAPFu"}]
0:{"P":null,"b":"5hTOFQgAyP0gWgEA_2kpB","c":["","posts","triton","tritonwithcuda",""],"q":"","i":false,"f":[[["",{"children":["posts",{"children":[["slug","triton/tritonwithcuda","c"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/blog/_next/static/chunks/743a8f8bdb738f7f.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","script","script-0",{"src":"/blog/_next/static/chunks/796e69ae18b2784c.js","async":true,"nonce":"$undefined"}]],["$","html",null,{"lang":"ko","children":[["$","head",null,{"children":["$","link",null,{"rel":"stylesheet","href":"https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css","integrity":"sha384-n8MVd4RsNIU0KOVEMVIqhKyMVPsoloXttrTHYUjDkaWaXIhKbMCh2GbqNl2CAPFu","crossOrigin":"anonymous"}]}],["$","body",null,{"children":["$","main",null,{"children":[["$","header",null,{"style":{"display":"flex","justifyContent":"space-between","alignItems":"baseline","gap":12},"children":[["$","h1",null,{"style":{"margin":"8px 0"},"children":["$","$L2",null,{"href":"/","style":{"textDecoration":"none"},"children":"CPIST's blog"}]}],["$","nav",null,{"style":{"display":"flex","gap":12},"children":["$","$L2",null,{"href":"/posts","children":"Posts"}]}]]}],["$","hr",null,{"style":{"border":0,"borderTop":"1px solid #eee","margin":"12px 0 24px"}}],["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}],["$","footer",null,{"style":{"marginTop":48,"paddingTop":16,"borderTop":"1px solid #eee","color":"#666"},"children":["© ",2026," CPIST's blog"]}]]}]}]]}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":["$L5",[["$","script","script-0",{"src":"/blog/_next/static/chunks/631eeae4923b8465.js","async":true,"nonce":"$undefined"}]],["$","$L6",null,{"children":["$","$7",null,{"name":"Next.MetadataOutlet","children":"$@8"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],["$","$1","h",{"children":[null,["$","$L9",null,{"children":"$@a"}],["$","div",null,{"hidden":true,"children":["$","$Lb",null,{"children":["$","$7",null,{"name":"Next.Metadata","children":"$@c"}]}]}],null]}],false]],"m":"$undefined","G":["$d",[]],"S":true}
5:["$","article",null,{"style":{"maxWidth":"800px","margin":"0 auto","padding":"20px"},"children":[["$","div",null,{"style":{"color":"#666","marginBottom":6},"children":["$","a",null,{"href":"/triton","style":{"textDecoration":"none"},"children":["/","triton"]}]}],["$","h2",null,{"style":{"marginTop":0},"children":"Deep dive into Triton with CUDA"}],["$","div",null,{"style":{"color":"#666","marginBottom":18},"children":"2026-01-04"}],["$","p",null,{"style":{"color":"#333","fontStyle":"italic"},"children":"Analyze Triton with CUDA, TVM"}],["$","hr",null,{"style":{"border":0,"borderTop":"1px solid #eee","margin":"18px 0"}}],["$","div",null,{"className":"prose","style":{"lineHeight":1.6},"children":[["$","p",null,{"children":"Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations (2019) 는 MAPL 워크숍에서 발표된 논문임.\nTriton 의 구조에 대해 다루었고, 그 이후로도 시간은 많이 흘렀다.\nGPU 컴퓨팅 생태계는 급격하게 변화했는데, **Triton의 접근 방식(Tile-based)**이 결국 업계 표준의 일부가 되었다."}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"CUDA의 진화 (Hopper & Blackwell 아키텍처 등장)"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"2019년 (Volta/Ampere): 프로그래머가 스레드 단위로 데이터 이동을 하나하나 코딩해야 했음"}],"\n",["$","li",null,{"children":["2026년 (Hopper/Blackwell): 하드웨어 레벨에서 Triton과 유사한 추상화를 지원하기 시작","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":["TMA (Tensor Memory Accelerator): 글로벌 메모리에서 공유 메모리로 데이터를 복사하는 작업을 하드웨어가 비동기적으로 수행","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"이전에는 개발자가 ld.global 명령어로 직접 복사 했음"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["Thread Block Clusters: 여러 블록이 Distributed Shared Memory를 통해 협력할 수 있게 됨","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"더 거대한 타일링이 가능"}],"\n"]}],"\n"]}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":"즉, CUDA도 하드웨어적으로 데이터 이동의 복잡성을 줄이는 방향으로 발전했으나, 여전히 C++ 기반의 복잡한 문법과 수동 제어가 필요"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"TVM의 진화 (TVM Unity)"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"2019년: 고수준 그래프(Relay)와 저수준 텐서 표현(TIR)이 분리되어 있어 유연성이 떨어졌었음"}],"\n",["$","li",null,{"children":["2026년 (TVM Unity): **\"Cross-layer interaction\"**을 도입하여 그래프 최적화와 연산자(Operator) 최적화를 한 번에 수행","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"또한 Dynamic Shape(가변 크기 입력) 지원이 대폭 강화"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":"여전히 커널 작성 난이도는 Triton에 비해 높은 편"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"Triton의 위상 변화"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"2019년에는 실험적인 연구였지만, OpenAI에 인수된 후 PyTorch 2.0 (torch.compile)의 기본 백엔드가 됨."}],"\n",["$","li",null,{"children":"현재 대부분의 AI 엔지니어는 알게 모르게 Triton을 통해 GPU를 제어"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"CUDA vs. Triton 비교 분석\nCUDA에서 알아야 할 개념은 Shared Memory, Coalescing, Tiling & Fusion 이다.\n기존 CUDA의 Manual 방식과 Triton의 Compiler-Automated 방식을 비교해 볼 필요가 있음.\n(이건 옛날 2019년의 기준으로 보는게 더 의미 있음)"}],"\n"]}],"\n"]}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":"Shared Memory (SRAM): 데이터 이동 최소화\n메모리(HBM)에서 데이터를 가져오는 것은 매우 느리기 때문에, 빠른 캐시인 Shared Memory(SRAM)를 잘 쓰는 것이 성능의 핵심"}],"\n"]}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":["CUDA는 Explicit Management (명시적 관리)를 씀","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":["개발자가 ",["$","strong",null,{"children":"shared"}]," 키워드로 변수를 선언"]}],"\n",["$","li",null,{"children":"글로벌 메모리에서 데이터를 읽어와(load) 저장(store)하고"}],"\n",["$","li",null,{"children":"다 읽을 때까지 기다리는(__syncthreads()) 코드를 직접 작성"}],"\n",["$","li",null,{"children":"문제점이라면 Bank Conflict(메모리 충돌)를 피하기 위해 패딩(Padding)을 넣는 등 하드웨어 구조를 빠삭하게 알아야 함."}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["반면 Trition은 Automatic Allocation (자동 할당) 을 씀","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"개발자는 \"이 데이터를 쓸 거야\"라고 선언만 하면"}],"\n",["$","li",null,{"children":"컴파일러의 Shared Memory Allocation Pass가 데이터의 **Live Range(생존 구간)**를 분석하고"}],"\n",["$","li",null,{"children":"자동으로 SRAM에 할당하고 관리"}],"\n",["$","li",null,{"children":"컴파일러가 알아서 최적의 위치에 배치하므로, 개발자는 알고리즘 로직에만 집중"}],"\n"]}],"\n"]}],"\n"]}],"\n",["$","ol",null,{"start":"2","children":["\n",["$","li",null,{"children":"Coalesced Memory Access: 메모리 대역폭 낭비 방지\nGPU는 한 번에 32개(Warp)의 스레드가 메모리에 접근\n이때 32개의 주소가 연속적이지 않으면(흩어져 있으면), 메모리 요청을 여러 번 보내야 해서 속도가 급격히 느려짐."}],"\n"]}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":["CUDA는 Manual Indexing (수동 인덱스 계산)을 사용함.","\n","$Le","\n"]}],"\n","$Lf","\n"]}],"\n","$L10","\n","$L11","\n","$L12","\n","$L13","\n","$L14","\n","$L15","\n","$L16"]}],"$L17","$L18"]}]
19:I[80852,["/blog/_next/static/chunks/796e69ae18b2784c.js","/blog/_next/static/chunks/631eeae4923b8465.js"],"default"]
e:["$","ul",null,{"children":["\n",["$","li",null,{"children":["개발자가 스레드 ID(threadIdx.x)를 계산할 때, 인접한 스레드가 인접한 메모리 주소(k, k+1, k+2...)를 읽도록 수식을 아주 정교하게 짜야함","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"예시로 row-major vs col-major 고려할 때"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":"실수로 인덱스 계산을 잘못하면 성능이 1/10로 떨어진다.."}],"\n"]}]
f:["$","li",null,{"children":["Triton은 Automatic Thread Reordering (자동 스레드 재배치)","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"개발자는 그냥 \"블록 단위\" (load(ptr + range))로 코드를 짬."}],"\n",["$","li",null,{"children":"Triton 컴파일러 백엔드가 Memory Coalescing Pass를 통해"}],"\n",["$","li",null,{"children":"실제 GPU 스레드가 실행될 순서를 내부적으로 뒤바꿔서(reorder) 메모리 접근을 묶어줌."}],"\n",["$","li",null,{"children":"논리적인 블록 구조만 잘 정의하면, 물리적인 접근 최적화는 컴파일러가 담당하는 구조"}],"\n"]}],"\n"]}]
10:["$","ol",null,{"start":"3","children":["\n",["$","li",null,{"children":"Tiling & Fusion: 거대한 행렬 쪼개기 및 합치기\n거대한 행렬 곱셈이나 Convolution을 할 때, 한 번에 처리할 수 없으므로 작은 타일(Tile)로 쪼개야 하고\n여러 연산(곱하기+더하기+ReLU)을 하나로 합쳐야(Fusion) 메모리 갔다 오는 횟수를 줄일 수 있음."}],"\n"]}]
11:["$","ul",null,{"children":["\n",["$","li",null,{"children":["CUDA는 Manual Loops & Kernel Fusion 을 사용함.","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"타일링을 위해 3~4중 for 루프를 작성하고, 경계 조건(if (idx < N))을 일일이 검사"}],"\n",["$","li",null,{"children":"Fusion을 하려면 MatMul 커널과 ReLU 커널을 합친 새로운 C++ 커널을 다시 짜야 합니다(Monolithic Kernel)"}],"\n",["$","li",null,{"children":["최적화를 위해 Hierarchical Tiling(L2 캐시 타일 ",["$","code",null,{"children":"->"}]," L1 캐시 타일 ",["$","code",null,{"children":"->"}]," 레지스터 타일)을 손으로 구현해야 해서 코드가 매우 길어짐"]}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["반면 Triton은 Tile Semantics & Automatic Fusion 을 사용함.","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"언어 차원에서 **Tile(block)**이 기본 타입임"}],"\n",["$","li",null,{"children":"C = dot(A, B) + Bias 처럼 쓰면, 컴파일러가 알아서 루프를 만들고 레지스터단에서 연산을 합쳐버립니다(Kernel Fusion)"}],"\n",["$","li",null,{"children":"논문에서는 Hierarchical Tiling Pass가 이 다단계 타일링 구조를 자동으로 생성한다고 설명"}],"\n"]}],"\n"]}],"\n"]}]
12:["$","ol",null,{"start":"5","children":["\n",["$","li",null,{"children":"그러면 Triton은 짱짱이야?\nTriton 역시 단점과 한계가 있음.\nTriton은 **\"행렬 연산(Matrix Multiplication)과 같이 블록(Tile) 단위로 쪼개지는 연산\"**에 특화되어 있음.\n이 범위를 벗어나면 CUDA보다 불편하거나 비효율적일 수 있음."}],"\n"]}]
13:["$","ul",null,{"children":["\n",["$","li",null,{"children":["표현력의 한계 (Expressiveness)","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"불규칙한 데이터 접근: 희소 행렬(Sparse Matrix)이나 그래프 알고리즘(Graph Traversal)처럼 메모리 접근이 불규칙한 알고리즘은 Triton의 '블록' 구조로 표현하기 매우 어려움"}],"\n",["$","li",null,{"children":["복잡한 제어 흐름: 스레드마다 제어 흐름이 제각각인(Divergent Control Flow) 복잡한 로직은 CUDA로 짜는 것이 훨씬 직관적이고 효율적","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"Triton은 구조적으로 이를 단순화(block 단위 처리)하려고 하기 때문"}],"\n"]}],"\n"]}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["미세 제어 불가 (Lack of Fine-grained Control)","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"레지스터 레벨 튜닝: CUDA 장인들은 레지스터 할당이나 명령어 스케줄링(Instruction Scheduling)까지 수동으로 조절해 극한의 성능을 쥐어짬."}],"\n",["$","li",null,{"children":"Triton은 이를 컴파일러에게 맡기므로, 컴파일러가 최적의 답을 찾지 못하면 사람이 개입해서 수정하기가 어려움."}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["디버깅과 프로파일링","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"CUDA는 지난 15년 넘게 쌓인 방대한 디버깅 툴(Nsight Systems, Nsight Compute 등)과 생태계가 있음"}],"\n",["$","li",null,{"children":"Triton은 생성된 코드(PTX/LLVM IR)를 디버깅해야 하는 경우가 많아, 문제 발생 시 원인을 찾기가 더 까다로울 수 있음."}],"\n"]}],"\n"]}],"\n"]}]
14:["$","ol",null,{"start":"6","children":["\n",["$","li",null,{"children":"그래서 용도별로 다르게 써야 한다."}],"\n"]}]
15:["$","ul",null,{"children":["\n",["$","li",null,{"children":["Triton 은 AI 커널 개발 (PyTorch) 사용함","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"적은 코드로 고성능 달성 (가성비 최고)"}],"\n",["$","li",null,{"children":"블록 연산 외에는 구현 난해하다는 건 문제"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["CUDA는 말 그대로 범용 GPU 프로그래밍의 끝판왕","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"하드웨어 제어권 100%, 모든 기능 구현 가능"}],"\n",["$","li",null,{"children":"배우기 어렵고 코드 작성이 김"}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":["TVM은 다양한 하드웨어 배포에 포커싱이 맞춰짐.","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"다양한 칩(NPU, ARM, DSP 등) 지원"}],"\n",["$","li",null,{"children":"설정과 최적화 과정이 복잡할 수 있음"}],"\n"]}],"\n"]}],"\n"]}]
16:["$","p",null,{"children":"Triton 은 물리 시뮬레이션, 렌더링 엔진(게임), 암호화폐 채굴 등 전통적인 병렬 컴퓨팅 분야에서는 못쓴다는 것이다."}]
17:["$","hr",null,{"style":{"border":0,"borderTop":"1px solid #eee","margin":"36px 0"}}]
18:["$","$L19",null,{}]
a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
1a:I[27201,["/blog/_next/static/chunks/ff1a16fafef87110.js","/blog/_next/static/chunks/247eb132b7f7b574.js"],"IconMark"]
c:[["$","title","0",{"children":"Deep dive into Triton with CUDA - CPIST's blog"}],["$","meta","1",{"name":"description","content":"Analyze Triton with CUDA, TVM"}],["$","link","2",{"rel":"icon","href":"/blog/favicon.ico?favicon.0b3bf435.ico","sizes":"256x256","type":"image/x-icon"}],["$","$L1a","3",{}]]
8:null
