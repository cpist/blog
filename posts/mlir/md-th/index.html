<!DOCTYPE html><!--zYjUf9OnkcNULfKVXPSuW--><html lang="ko"><head><meta charSet="utf-8"/><link rel="preconnect" href="/" crossorigin=""/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/blog/_next/static/chunks/d335db6b3f1a2619.css" data-precedence="next"/><link rel="stylesheet" href="/blog/_next/static/chunks/4057cc9dbcc744c0.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/blog/_next/static/chunks/2139e000f4b5d584.js"/><script src="/blog/_next/static/chunks/8a8ef77865bda9e6.js" async=""></script><script src="/blog/_next/static/chunks/0ff423a9fcc0186e.js" async=""></script><script src="/blog/_next/static/chunks/88a8688d62cd2814.js" async=""></script><script src="/blog/_next/static/chunks/turbopack-566b9f8f22ac84c4.js" async=""></script><script src="/blog/_next/static/chunks/796e69ae18b2784c.js" async=""></script><script src="/blog/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/blog/_next/static/chunks/247eb132b7f7b574.js" async=""></script><script src="/blog/_next/static/chunks/631eeae4923b8465.js" async=""></script><link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" as="style" crossorigin="anonymous" integrity="sha384-n8MVd4RsNIU0KOVEMVIqhKyMVPsoloXttrTHYUjDkaWaXIhKbMCh2GbqNl2CAPFu"/><title>MLIR Transform Tutorial Ch H 에 대하여 - CPIST&#x27;s blog</title><meta name="description" content="Reproducing Halide Schedule"/><link rel="icon" href="/blog/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0KOVEMVIqhKyMVPsoloXttrTHYUjDkaWaXIhKbMCh2GbqNl2CAPFu" crossorigin="anonymous"/><script src="/blog/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body><div hidden=""><!--$--><!--/$--></div><main><header style="display:flex;justify-content:space-between;align-items:baseline;gap:12px"><h1 style="margin:8px 0"><a style="text-decoration:none" href="/blog/">CPIST&#x27;s blog</a></h1><nav style="display:flex;gap:12px"><a href="/blog/posts/">Posts</a></nav></header><hr style="border:0;border-top:1px solid #eee;margin:12px 0 24px"/><article style="max-width:800px;margin:0 auto;padding:20px"><div style="color:#666;margin-bottom:6px"><a href="/mlir" style="text-decoration:none">/<!-- -->mlir</a></div><h2 style="margin-top:0">MLIR Transform Tutorial Ch H 에 대하여</h2><div style="color:#666;margin-bottom:18px">2025-12-06</div><p style="color:#333;font-style:italic">Reproducing Halide Schedule</p><hr style="border:0;border-top:1px solid #eee;margin:18px 0"/><div class="prose" style="line-height:1.6"><ol>
<li>Halide VS MLIR
Halide의 강점은</li>
</ol>
<ul>
<li>계산(what) 과 스케줄(how) 를 완전히 분리했다는 점</li>
<li>같은 계산이라도<!-- -->
<ul>
<li>split</li>
<li>reorder</li>
<li>vectorize</li>
<li>unroll</li>
<li>compute_at 같은 스케줄만 바꿔서 성능을 극단적으로 끌어 올렸음.</li>
</ul>
</li>
</ul>
<ul>
<li>MLIR의 경우</li>
</ul>
<ul>
<li>MLIR은 기본적으로 각 연산이 각자 루프를 가진 분산된 형태임.</li>
<li>Halide는 여러 연산이 암묵적으로 하나의 큰 루프에 융합된 형태임.</li>
<li>따라서 Halide 스케줄을 MLIR 식으로 흉내 내보는 것이 이 챕터에서 다루는 내용</li>
</ul>
<ol start="2">
<li>Channeled 2D Convolution + ReLU
Halide 코드는</li>
</ol>
<ul>
<li>입력: input[N][H+2][W+2][CI]</li>
<li>필터: filter[CO][3][3][CI]</li>
<li>연산:<!-- -->
<ol>
<li>bias로 초기화</li>
<li>3중 reduction (CI, 3x3)</li>
<li>ReLU</li>
</ol>
</li>
</ul>
<ul>
<li>MLIR 에서는</li>
</ul>
<ul>
<li>linalg.generic 으로 convolution 재현</li>
<li>bias 초기화 / conv / relu가 각각 다른 연산</li>
<li>즉 루프가 완전히 분리되어 있음</li>
</ul>
<p>루프 구조를 코드로 보자면</p>
<pre><code>// Halide는 완전 융합 되어 있고
for n, y, x, c:
  conv = bias
  for rz, ry, rx:
    conv += filter * input
  relu = max(0, conv)

// Linalg는 완전 분산되어 있음
for n, y, x, c:
  init
for n, y, x, c:
  conv update
for n, y, x, c:
  relu
</code></pre>
<p>이러한 차이를 Transform dialect로 다시 합치는 것이 과제이다.</p>
<ol start="3">
<li>Halide 스케줄을 Transform dialect에 Mapping 하자.
즉 Halide 스케줄 <code>-&gt;</code> MLIR Transform 에서는</li>
</ol>
<ul>
<li>
<p>split을 tile_using_forall 로</p>
</li>
<li>
<p>reorder를 tile 순서 + interchange로</p>
</li>
<li>
<p>compute_at을 fuse_into_containing_op 로</p>
</li>
<li>
<p>vectorize 를 structured.vectorize_* 로</p>
</li>
<li>
<p>unroll 을 transform.loop.unroll 로</p>
</li>
<li>
<p>MLIR은 암묵 루프를 유지하려 하고</p>
</li>
<li>
<p>Halide는 루프를 적극적으로 쪼개고 재배열 하려 하고</p>
</li>
</ul>
<ol start="4">
<li>ReLU 루프 구조 재현
Halide가 원하는 형태는 아래와 같음</li>
</ol>
<pre><code>for co
  for n
    for y
      for xo
        for xi
          for ci
            relu(...)
</code></pre>
<p>MLIR의 경우</p>
<ol>
<li>먼저 c 차원을 tile <code>-&gt;</code> co</li>
<li>나머지 (n,y,x) 를 tile</li>
<li>forall 루프로 명시적인 루프를 생성
그 결과</li>
</ol>
<ul>
<li>scf.forall + 내부 linalg.elementwise</li>
<li>Halide와 거의 같은 루프 계층이 생성됨.</li>
</ul>
<ol start="5">
<li>compute_at: Conv를 ReLU 안으로 밀어 넣는 것
Halide</li>
</ol>
<pre><code>conv.compute_at(relu, xo)
</code></pre>
<p>MLIR은</p>
<ul>
<li>producer <code>-&gt;</code> consumer fusion</li>
<li>두 단계:<!-- -->
<ul>
<li>conv update -&gt; relu 루프에 fuse</li>
<li>bias init -&gt; conv+relu 루프에 fuse</li>
</ul>
</li>
</ul>
<p>사용한 도구는</p>
<pre><code>transform.structured.fuse_into_containing_op
</code></pre>
<p>이렇게 해서 Halide의 한 루프안에 다 있음 구조를 재현할 수 있음.</p>
<ol start="6">
<li>Reduction 루프(rz, ry, rx) 처리</li>
</ol>
<ul>
<li>reduction은 병렬 forall 이 안됨</li>
<li>이를 해결하기 위해 아래와 같이 함.</li>
</ul>
<pre><code>transform.structured.tile_reduction_using_for
</code></pre>
<p>효과는</p>
<ul>
<li>scf.for 로 reduction 루프를 생성하고</li>
<li>내부적으로 partial reduction + combiner를 생성하고</li>
<li>fastmath 덕분에 연산 순서 변경도 가능해 진다.</li>
</ul>
<ol start="7">
<li>벡터화를 위한 마지막 타일링</li>
</ol>
<ul>
<li>ci 차원이 vector size (ex :16) 을 유지하려고 한다면</li>
<li>아래와 같이 함.</li>
</ul>
<pre><code>tile_sizes = [0, 0, 1, 16]
</code></pre>
<p>이걸</p>
<ul>
<li>conv</li>
<li>bias</li>
<li>relu</li>
<li>combiner 모두에 적용하는 것</li>
<li>vector 화 전에 tensor 형태를 일부러 &quot;16짜리&quot; 로 유지</li>
</ul>
<ol start="8">
<li>unroll의 함정
Halide 스케줄은</li>
</ol>
<ul>
<li>unroll(ci)</li>
<li>unroll(xi)</li>
</ul>
<p>처음에는 transform 단계에서 바로 unroll 하려고 했지만
이것은 성능에서 완전하게 망했음 (14 GFLOPS, 22% peak)</p>
<p>그 이유는</p>
<ul>
<li>Tensor SSA 모델 + 조기 unroll</li>
<li>IR이 너무 길어지고</li>
<li>load / fma / store가 섞여서 레지스터 재사용이 불가능해짐</li>
<li>즉 너무 일찍 unroll 하면 컴파일러가 포기해 버림.</li>
</ul>
<ol start="9">
<li>이를 해결하기 위한 방법중 하나가 bufferization 이후 unroll</li>
</ol>
<ol>
<li>bufferize를 먼저하고</li>
<li>다시 loop 매칭한 다음</li>
<li>그 다음 unroll을 하는것</li>
</ol>
<p>그 결과</p>
<ul>
<li>Halide와 거의 동일한 어셈블리</li>
<li>실행 시간: ~120ms</li>
<li>성능은 77% of peak</li>
</ul>
<p>단점은</p>
<ul>
<li>Transform handle의 철학을 약간 거스른 방법임.</li>
</ul>
<ol start="10">
<li>그래서 다차원 벡터를 사용함
<code>vector&lt;5x64xf32&gt;</code> 루프 5x4 를 만들고 unroll 한것과 같음</li>
</ol>
<ul>
<li>굳이 xi/ci 루프를 만들고 unroll 하지 않아도</li>
<li>다차원 벡터 <code>-&gt;</code> 하드웨어 벡터로 lowering 과정에서 자동 분해함.
그 결과</li>
<li>unroll 단계를 제거하고</li>
<li>IR이 훨씬 짧아지고</li>
<li>load / broadcast / fma 정렬이 개선됨.</li>
</ul>
<p>성능 측면에서도</p>
<ul>
<li>~110ms / 84% of peak / Halide 보다도 약간 빠름</li>
</ul>
<p>=====================================================================</p>
<p>요약해 보자면</p>
<ul>
<li>Transform dialect는 Schedule DSL의 IR 이라는 점</li>
<li>Halide Schedule은 MLIR로 거의 1:1 재현이 가능하다</li>
<li>변환 순서가 성능을 결정함.<!-- -->
<ul>
<li>unroll이 특히</li>
</ul>
</li>
<li>Tensor SSA + 조기 unroll = 성능 최악</li>
<li>다차원 벡터는 &quot;암묵적 unroll + 타일링임&quot;</li>
<li>MLIR은<!-- -->
<ul>
<li>덜 건드리고</li>
<li>나중에 낮은 레벨에서 터뜨릴수록 성능이 좋아짐.</li>
</ul>
</li>
</ul></div><hr style="border:0;border-top:1px solid #eee;margin:36px 0"/><div></div></article><!--$--><!--/$--><footer style="margin-top:48px;padding-top:16px;border-top:1px solid #eee;color:#666">© <!-- -->2026<!-- --> CPIST&#x27;s blog</footer></main><script src="/blog/_next/static/chunks/2139e000f4b5d584.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[22016,[\"/blog/_next/static/chunks/796e69ae18b2784c.js\"],\"\"]\n3:I[39756,[\"/blog/_next/static/chunks/ff1a16fafef87110.js\",\"/blog/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n4:I[37457,[\"/blog/_next/static/chunks/ff1a16fafef87110.js\",\"/blog/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n6:I[97367,[\"/blog/_next/static/chunks/ff1a16fafef87110.js\",\"/blog/_next/static/chunks/247eb132b7f7b574.js\"],\"OutletBoundary\"]\n7:\"$Sreact.suspense\"\n9:I[97367,[\"/blog/_next/static/chunks/ff1a16fafef87110.js\",\"/blog/_next/static/chunks/247eb132b7f7b574.js\"],\"ViewportBoundary\"]\nb:I[97367,[\"/blog/_next/static/chunks/ff1a16fafef87110.js\",\"/blog/_next/static/chunks/247eb132b7f7b574.js\"],\"MetadataBoundary\"]\nd:I[68027,[],\"default\"]\n:HL[\"/blog/_next/static/chunks/d335db6b3f1a2619.css\",\"style\"]\n:HC[\"/\",\"\"]\n:HL[\"/blog/_next/static/chunks/4057cc9dbcc744c0.css\",\"style\"]\n:HL[\"https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css\",\"style\",{\"crossOrigin\":\"anonymous\",\"integrity\":\"sha384-n8MVd4RsNIU0KOVEMVIqhKyMVPsoloXttrTHYUjDkaWaXIhKbMCh2GbqNl2CAPFu\"}]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"zYjUf9OnkcNULfKVXPSuW\",\"c\":[\"\",\"posts\",\"mlir\",\"md-th\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"posts\",{\"children\":[[\"slug\",\"mlir/md-th\",\"c\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/blog/_next/static/chunks/d335db6b3f1a2619.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/blog/_next/static/chunks/796e69ae18b2784c.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"ko\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css\",\"integrity\":\"sha384-n8MVd4RsNIU0KOVEMVIqhKyMVPsoloXttrTHYUjDkaWaXIhKbMCh2GbqNl2CAPFu\",\"crossOrigin\":\"anonymous\"}]}],[\"$\",\"body\",null,{\"children\":[\"$\",\"main\",null,{\"children\":[[\"$\",\"header\",null,{\"style\":{\"display\":\"flex\",\"justifyContent\":\"space-between\",\"alignItems\":\"baseline\",\"gap\":12},\"children\":[[\"$\",\"h1\",null,{\"style\":{\"margin\":\"8px 0\"},\"children\":[\"$\",\"$L2\",null,{\"href\":\"/\",\"style\":{\"textDecoration\":\"none\"},\"children\":\"CPIST's blog\"}]}],[\"$\",\"nav\",null,{\"style\":{\"display\":\"flex\",\"gap\":12},\"children\":[\"$\",\"$L2\",null,{\"href\":\"/posts\",\"children\":\"Posts\"}]}]]}],[\"$\",\"hr\",null,{\"style\":{\"border\":0,\"borderTop\":\"1px solid #eee\",\"margin\":\"12px 0 24px\"}}],[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"footer\",null,{\"style\":{\"marginTop\":48,\"paddingTop\":16,\"borderTop\":\"1px solid #eee\",\"color\":\"#666\"},\"children\":[\"© \",2026,\" CPIST's blog\"]}]]}]}]]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/blog/_next/static/chunks/4057cc9dbcc744c0.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/blog/_next/static/chunks/631eeae4923b8465.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L6\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@8\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L9\",null,{\"children\":\"$@a\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@c\"}]}]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"article\",null,{\"style\":{\"maxWidth\":\"800px\",\"margin\":\"0 auto\",\"padding\":\"20px\"},\"children\":[[\"$\",\"div\",null,{\"style\":{\"color\":\"#666\",\"marginBottom\":6},\"children\":[\"$\",\"a\",null,{\"href\":\"/mlir\",\"style\":{\"textDecoration\":\"none\"},\"children\":[\"/\",\"mlir\"]}]}],[\"$\",\"h2\",null,{\"style\":{\"marginTop\":0},\"children\":\"MLIR Transform Tutorial Ch H 에 대하여\"}],[\"$\",\"div\",null,{\"style\":{\"color\":\"#666\",\"marginBottom\":18},\"children\":\"2025-12-06\"}],[\"$\",\"p\",null,{\"style\":{\"color\":\"#333\",\"fontStyle\":\"italic\"},\"children\":\"Reproducing Halide Schedule\"}],[\"$\",\"hr\",null,{\"style\":{\"border\":0,\"borderTop\":\"1px solid #eee\",\"margin\":\"18px 0\"}}],[\"$\",\"div\",null,{\"className\":\"prose\",\"style\":{\"lineHeight\":1.6},\"children\":[[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Halide VS MLIR\\nHalide의 강점은\"}],\"\\n\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"계산(what) 과 스케줄(how) 를 완전히 분리했다는 점\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"같은 계산이라도\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"split\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"reorder\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"vectorize\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"unroll\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"compute_at 같은 스케줄만 바꿔서 성능을 극단적으로 끌어 올렸음.\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"MLIR의 경우\"}],\"\\n\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"MLIR은 기본적으로 각 연산이 각자 루프를 가진 분산된 형태임.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Halide는 여러 연산이 암묵적으로 하나의 큰 루프에 융합된 형태임.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"따라서 Halide 스케줄을 MLIR 식으로 흉내 내보는 것이 이 챕터에서 다루는 내용\"}],\"\\n\"]}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"2\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Channeled 2D Convolution + ReLU\\nHalide 코드는\"}],\"\\n\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"입력: input[N][H+2][W+2][CI]\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"필터: filter[CO][3][3][CI]\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"연산:\",\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"bias로 초기화\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"3중 reduction (CI, 3x3)\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"ReLU\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"MLIR 에서는\"}],\"\\n\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"linalg.generic 으로 convolution 재현\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"bias 초기화 / conv / relu가 각각 다른 연산\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"즉 루프가 완전히 분리되어 있음\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"루프 구조를 코드로 보자면\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"// Halide는 완전 융합 되어 있고\\nfor n, y, x, c:\\n  conv = bias\\n  for rz, ry, rx:\\n    conv += filter * input\\n  relu = max(0, conv)\\n\\n// Linalg는 완전 분산되어 있음\\nfor n, y, x, c:\\n  init\\nfor n, y, x, c:\\n  conv update\\nfor n, y, x, c:\\n  relu\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이러한 차이를 Transform dialect로 다시 합치는 것이 과제이다.\"}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"3\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Halide 스케줄을 Transform dialect에 Mapping 하자.\\n즉 Halide 스케줄 \",[\"$\",\"code\",null,{\"children\":\"-\u003e\"}],\" MLIR Transform 에서는\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"split을 tile_using_forall 로\"}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"reorder를 tile 순서 + interchange로\"}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"compute_at을 fuse_into_containing_op 로\"}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"vectorize 를 structured.vectorize_* 로\"}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"unroll 을 transform.loop.unroll 로\"}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"MLIR은 암묵 루프를 유지하려 하고\"}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"Halide는 루프를 적극적으로 쪼개고 재배열 하려 하고\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"4\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"ReLU 루프 구조 재현\\nHalide가 원하는 형태는 아래와 같음\"}],\"\\n\"]}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"for co\\n  for n\\n    for y\\n      for xo\\n        for xi\\n          for ci\\n            relu(...)\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"MLIR의 경우\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"먼저 c 차원을 tile \",[\"$\",\"code\",null,{\"children\":\"-\u003e\"}],\" co\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"나머지 (n,y,x) 를 tile\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"forall 루프로 명시적인 루프를 생성\\n그 결과\"}],\"\\n\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"scf.forall + 내부 linalg.elementwise\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Halide와 거의 같은 루프 계층이 생성됨.\"}],\"\\n\"]}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"5\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"compute_at: Conv를 ReLU 안으로 밀어 넣는 것\\nHalide\"}],\"\\n\"]}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"conv.compute_at(relu, xo)\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"MLIR은\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"producer \",\"$Le\",\" consumer fusion\"]}],\"\\n\",\"$Lf\",\"\\n\"]}],\"\\n\",\"$L10\",\"\\n\",\"$L11\",\"\\n\",\"$L12\",\"\\n\",\"$L13\",\"\\n\",\"$L14\",\"\\n\",\"$L15\",\"\\n\",\"$L16\",\"\\n\",\"$L17\",\"\\n\",\"$L18\",\"\\n\",\"$L19\",\"\\n\",\"$L1a\",\"\\n\",\"$L1b\",\"\\n\",\"$L1c\",\"\\n\",\"$L1d\",\"\\n\",\"$L1e\",\"\\n\",\"$L1f\",\"\\n\",\"$L20\",\"\\n\",\"$L21\",\"\\n\",\"$L22\",\"\\n\",\"$L23\",\"\\n\",\"$L24\",\"\\n\",\"$L25\",\"\\n\",\"$L26\",\"\\n\",\"$L27\",\"\\n\",\"$L28\",\"\\n\",\"$L29\",\"\\n\",\"$L2a\",\"\\n\",\"$L2b\",\"\\n\",\"$L2c\",\"\\n\",\"$L2d\",\"\\n\",\"$L2e\"]}],\"$L2f\",\"$L30\"]}]\n"])</script><script>self.__next_f.push([1,"31:I[80852,[\"/blog/_next/static/chunks/796e69ae18b2784c.js\",\"/blog/_next/static/chunks/631eeae4923b8465.js\"],\"default\"]\ne:[\"$\",\"code\",null,{\"children\":\"-\u003e\"}]\nf:[\"$\",\"li\",null,{\"children\":[\"두 단계:\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"conv update -\u003e relu 루프에 fuse\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"bias init -\u003e conv+relu 루프에 fuse\"}],\"\\n\"]}],\"\\n\"]}]\n10:[\"$\",\"p\",null,{\"children\":\"사용한 도구는\"}]\n11:[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"transform.structured.fuse_into_containing_op\\n\"}]}]\n12:[\"$\",\"p\",null,{\"children\":\"이렇게 해서 Halide의 한 루프안에 다 있음 구조를 재현할 수 있음.\"}]\n13:[\"$\",\"ol\",null,{\"start\":\"6\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Reduction 루프(rz, ry, rx) 처리\"}],\"\\n\"]}]\n14:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"reduction은 병렬 forall 이 안됨\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"이를 해결하기 위해 아래와 같이 함.\"}],\"\\n\"]}]\n15:[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"transform.structured.tile_reduction_using_for\\n\"}]}]\n16:[\"$\",\"p\",null,{\"children\":\"효과는\"}]\n17:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"scf.for 로 reduction 루프를 생성하고\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"내부적으로 partial reduction + combiner를 생성하고\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"fastmath 덕분에 연산 순서 변경도 가능해 진다.\"}],\"\\n\"]}]\n18:[\"$\",\"ol\",null,{\"start\":\"7\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"벡터화를 위한 마지막 타일링\"}],\"\\n\"]}]\n19:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"ci 차원이 vector size (ex :16) 을 유지하려고 한다면\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"아래와 같이 함.\"}],\"\\n\"]}]\n1a:[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"tile_sizes = [0, 0, 1, 16]\\n\"}]}]\n1b:[\"$\",\"p\",null,{\"children\":\"이걸\"}]\n1c:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"conv\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"bias\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"relu\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"combiner 모두에 적용하는 것\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"vector 화 전에 tensor 형태를 일부러 \\\"16짜리\\\" 로 유지\"}],\"\\n\"]}]\n1d:[\"$\",\"ol\",null,{\"start\":\"8\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"unroll의 함정\\nHalide 스케줄은\"}],\"\\n\"]}]\n1e:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"unroll(ci)\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"unroll(xi)\"}],\"\\n\"]}]\n1f:[\"$\",\"p\",null,{\"children\":\"처음에는 transform 단계에서 바로 unroll 하려고 했지만\\n이것은 성능에서 완전하게 망했음 (14 GFLOPS, 22% peak)\"}]\n20:[\"$\",\"p\",null,{\"children\":\"그 이유는\"}]\n21:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Tensor SSA 모델 + 조기 unroll\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"IR이 너무 길어지고\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"load / fma / store가 섞여서 레지스터 재사용이 불가능해짐\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"즉 너무 일찍 unroll 하면 컴파일러가 포기해 버림.\"}],\"\\n\"]}]\n22:[\"$\",\"ol\",null,{\"start\":\"9\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"이를 해결하기 위한 방법중 하나가 bufferization 이후 unroll\"}],\"\\n\"]}]\n23:[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"bufferize를 먼저하고\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"다시 loop 매칭한 다음\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"그 다음 unroll을 하는것\"}],\"\\n\"]}]\n24:[\"$\",\"p\",null,{\"children\":\"그 결과\"}]\n25:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Halide와 거의 동일한 어셈블리\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"실행 시간: ~120ms\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"성능은 77% of peak\"}],\"\\n\"]}]\n26:[\"$\",\"p\",null,{\"children\":\"단점은\"}]\n27:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Transform handle의 철학을 약간 거스른 방법임.\"}],\"\\n\"]}]\n28:[\"$\",\"ol\",null,{\"start\":\"10\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"그래서 다차원 벡터를 사용함\\"])</script><script>self.__next_f.push([1,"n\",[\"$\",\"code\",null,{\"children\":\"vector\u003c5x64xf32\u003e\"}],\" 루프 5x4 를 만들고 unroll 한것과 같음\"]}],\"\\n\"]}]\n29:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"굳이 xi/ci 루프를 만들고 unroll 하지 않아도\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"다차원 벡터 \",[\"$\",\"code\",null,{\"children\":\"-\u003e\"}],\" 하드웨어 벡터로 lowering 과정에서 자동 분해함.\\n그 결과\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"unroll 단계를 제거하고\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"IR이 훨씬 짧아지고\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"load / broadcast / fma 정렬이 개선됨.\"}],\"\\n\"]}]\n2a:[\"$\",\"p\",null,{\"children\":\"성능 측면에서도\"}]\n2b:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"~110ms / 84% of peak / Halide 보다도 약간 빠름\"}],\"\\n\"]}]\n2c:[\"$\",\"p\",null,{\"children\":\"=====================================================================\"}]\n2d:[\"$\",\"p\",null,{\"children\":\"요약해 보자면\"}]\n2e:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Transform dialect는 Schedule DSL의 IR 이라는 점\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Halide Schedule은 MLIR로 거의 1:1 재현이 가능하다\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"변환 순서가 성능을 결정함.\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"unroll이 특히\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Tensor SSA + 조기 unroll = 성능 최악\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"다차원 벡터는 \\\"암묵적 unroll + 타일링임\\\"\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"MLIR은\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"덜 건드리고\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"나중에 낮은 레벨에서 터뜨릴수록 성능이 좋아짐.\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\"]}]\n2f:[\"$\",\"hr\",null,{\"style\":{\"border\":0,\"borderTop\":\"1px solid #eee\",\"margin\":\"36px 0\"}}]\n30:[\"$\",\"$L31\",null,{}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"32:I[27201,[\"/blog/_next/static/chunks/ff1a16fafef87110.js\",\"/blog/_next/static/chunks/247eb132b7f7b574.js\"],\"IconMark\"]\nc:[[\"$\",\"title\",\"0\",{\"children\":\"MLIR Transform Tutorial Ch H 에 대하여 - CPIST's blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Reproducing Halide Schedule\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/blog/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"$L32\",\"3\",{}]]\n8:null\n"])</script></body></html>