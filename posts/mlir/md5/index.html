<!DOCTYPE html><!--3vwnhP6rvgBy3ORnPg2gd--><html lang="ko"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/blog/_next/static/chunks/d335db6b3f1a2619.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/blog/_next/static/chunks/cbd55ab9639e1e66.js"/><script src="/blog/_next/static/chunks/8c4bb65ca9f95eb5.js" async=""></script><script src="/blog/_next/static/chunks/0ff423a9fcc0186e.js" async=""></script><script src="/blog/_next/static/chunks/88a8688d62cd2814.js" async=""></script><script src="/blog/_next/static/chunks/turbopack-8ff2f6efb1e78309.js" async=""></script><script src="/blog/_next/static/chunks/796e69ae18b2784c.js" async=""></script><script src="/blog/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/blog/_next/static/chunks/247eb132b7f7b574.js" async=""></script><title>MLIR Toy Tutorial Ch 5 에 대하여 - CPIST&#x27;s blog</title><meta name="description" content="Partially lowering to lower-level dialects. We&#x27;ll convert some of our high level language specific semantics towards a generic affine oriented dialect for optimization."/><link rel="icon" href="/blog/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><script src="/blog/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body><div hidden=""><!--$--><!--/$--></div><main><header style="display:flex;justify-content:space-between;align-items:baseline;gap:12px"><h1 style="margin:8px 0"><a style="text-decoration:none" href="/blog/">CPIST&#x27;s blog</a></h1><nav style="display:flex;gap:12px"><a href="/blog/posts/">Posts</a></nav></header><hr style="border:0;border-top:1px solid #eee;margin:12px 0 24px"/><article><div style="color:#666;margin-bottom:6px"><a href="/mlir" style="text-decoration:none">/<!-- -->mlir</a></div><h2 style="margin-top:0">MLIR Toy Tutorial Ch 5 에 대하여</h2><div style="color:#666;margin-bottom:18px">2025-11-08</div><p style="color:#333">Partially lowering to lower-level dialects. We&#x27;ll convert some of our high level language specific semantics towards a generic affine oriented dialect for optimization.</p><hr style="border:0;border-top:1px solid #eee;margin:18px 0"/><div class="prose"><ol>
<li>왜 Affine 이라는게 필요한가?
다루고 있는 Toy는 수학계산하기 좋다. tensor 를 기반으로 하는 값 개념이다. (메모리에 없는)</li>
</ol>
<ul>
<li>그런데 Affine은 반복문 &amp; 배열 최적화에 특화되어 있다.</li>
<li>memref 기반이고 이말인 즉슨 실제 메모리 비퍼이다.</li>
<li>따라서 계산-heavy 부분은 Affine 으로 / 출력(toy.print) 같은 건 <code>-&gt;</code> 나중에 LLVM에서 처리하면 된다.</li>
</ul>
<p>일단 Affine은 MLIR의 dialect 중 하나임. 근데 최적화를 위해 설계된 중간 단계 전용 dialect 임.</p>
<pre><code>affine::AffineDialect

기본적으로
affine.for
affine.if
afffine.load
affine.store
</code></pre>
<p>LLVM으로 바로 내려갈 수 없는 이유는</p>
<ul>
<li>포인터 연산이 너무 자유롭고</li>
<li>루프 구조 분석이 어렵고</li>
<li>이게 같은 배열을 접근하는지 추적이 힘든 LLVM의 특징 때문임.</li>
</ul>
<p>Affine은 메모리 접근이 수식으로 딱 떨어지고, 컴파일러가 안전하다는 것을 보장하게 해줌.</p>
<pre><code>// toy의 이 코드를
%y = toy.mul %x, %x

// Affine 에서는
affine.for i ...
  affine.for j ...
    %v = affine.load %buf[i, j]
    %r = arith.mulf %v, %v
    affine.store %r, %out[i, j]
</code></pre>
<p>이렇게 하여 연산 구조, 메모리 패턴, 반복 범위를 컴파일러 눈에 다 보이게 해줌.
루프와 메모리 접근을 수학적으로 깔끔하게 표현해서 컴파일러가 마음껏 최적화할 수 있게 만든 dialect 라는 것이다.</p>
<ol start="2">
<li>핵심 개념 1 : Dialect Conversion
MLIR에는 언어간 변환을 담당하는 DialectConversion Framework이 있다.
이를 쓰기 위해서는 3가지가 필요하다.
(1) Conversion Target
어디 까지 변환되면 성공인가? 즉 변환이 끝난 뒤 IR에 남아있는 op들이 이 집합(legal) 안에 있으면 성공이고, 하나라도 밖의 op가 있으면 실패이다.</li>
</ol>
<ul>
<li>허용되는 것은 Affine, Arith, Func, memref</li>
<li>금지 되는 것은 Toy dialect 전체</li>
<li>예외는 toy.print는 부분 lowering으로 남겨둠. 여기서도 toy.print의 입력은 tensor는 안되고 memref 여야 한다.</li>
</ul>
<p>(2) Rewrite Patterns
Toy 연산을 Affine으로 어떻게 바꿀까?</p>
<pre><code>toy.transpose
   ↓
affine.for + affine.load + affine.store
</code></pre>
<p>여기서 transpose는 중첩 loop 돌면서 인덱스를 뒤집어서 load / store 한다는 것을 알 수 있다.
좀더 자세히 살펴보자면 Toy는 아래와 같이 개념적 연산을 진행함. (행과 열을 바꾸는)</p>
<pre><code>%out = toy.transpose %in : tensor&lt;2x3&gt; -&gt; tensor&lt;3x2&gt;
</code></pre>
<p>여기서는 내부적으로 loop도 없고, 메모리 접근도 없으며, 그냥 값이 바뀐다는 선언임.
그런데 Affine에서는 transpose 같은 고수준 연산이 없기 때문에 이를 직접 말해줘야 함.</p>
<pre><code>affine.for i = 0 to 3 {
  affine.for j = 0 to 2 {
    ...
  }
}

// transpose의 규칙
out[i][j] = in[j][i]

// 그렇기에 아래처럼
%v = affine.load %input[j, i]
affine.store %v, %output[i, j]

// 코드에서는 실제 아래처럼 쓰임
SmallVector&lt;Value, 2&gt; reverseIvs(llvm::reverse(loopIvs));
return affine::AffineLoadOp::create(builder, loc, input, reverseIvs);
</code></pre>
<p>인덱스를 뒤집는 다는건, loop 변수 순서는 그대로 쓰지만, load 할때만 index 순서를 거꾸로 쓴다는 것.</p>
<p>(3) Type Converter
이 챕터에서는 안씀.
다만 tensor <code>-&gt;</code> memref 개념은 중요하다는 것. (이건 OpConversionPattern 안에서 명시적으로 처리함.)
tensor <code>-&gt;</code> memref는 새 버퍼를 만들고 값을 채우는 것.</p>
<ol start="3">
<li>Partial Lowering (부분 변환)
모든 Toy 연산을 없애지 않고</li>
</ol>
<ul>
<li>계산 <code>-&gt;</code> Affine 변환</li>
<li>출력 (toy.print) 는 그대로 두었다. (위에서도 나왔던)</li>
</ul>
<pre><code>// 아직 안바뀐 Toy 연산이 있어도 괜찮다는 것
applyPartialConversion(...)
</code></pre>
<ol start="4">
<li>tensor <code>&lt;-&gt;</code> memref를 어떻게 섞는가
toy.print는 원래 tensor 만 받지만, 우리는 memref를 쓰고 있는 상황</li>
</ol>
<p>선택지는 3가지이다.
(1) memref 를 tensor로 복사하는 것은 느리고 최적화가 안되있음.
(2) 새로운 toy.print_memref를 만드는 것은 번거롭다.
(3) toy.print가 memref도 받게 하는 것이다. (이 챕터에서 사용한 방법)</p>
<pre><code>// 현실적인 Toy dialect
AnyTypeOf&lt;[F64Tensor, F64MemRef]&gt;
</code></pre>
<ol start="5">
<li>Toy 코드에서 Affine 으로 낮춘 예제 한개를 더 보자.</li>
</ol>
<pre><code>%2 = toy.transpose(%0)
%3 = toy.mul %2, %2
toy.print %3
</code></pre>
<p>이를 Affine으로 낮추면</p>
<ul>
<li>tensor는 memref.alloc 으로</li>
<li>연산은 affine.for 로</li>
<li>곱셈은 affine.load + arith.mulf 로</li>
<li>출력은 toy.print memref 로</li>
</ul>
<ol start="6">
<li>첫 변환 결과는 다소 애매하다.
불필요한 버퍼를 썼고, 같은 값을 여러번 load 했기 때문이다.
이를 해결하는 방법은 LoopFusion 과 AffineScalarReplacement 이다.
이 결과 루프가 합쳐지고, load 중복이 제거 되고, 메모리 사용이 감소된다.</li>
</ol>
<p>=====================================================================</p>
<p>정리해 보자면</p>
<ul>
<li>Partial lowering 의 개념과</li>
<li>tensor -&gt; memref의 전환 이유</li>
<li>Affine dialect의 최적화 파워와</li>
<li>중간 단계 dialect의 가치에 대해 다루었다.</li>
</ul></div></article><!--$--><!--/$--><footer style="margin-top:48px;padding-top:16px;border-top:1px solid #eee;color:#666">© <!-- -->2025<!-- --> CPIST&#x27;s blog</footer></main><script src="/blog/_next/static/chunks/cbd55ab9639e1e66.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[22016,[\"/blog/_next/static/chunks/796e69ae18b2784c.js\"],\"\"]\n3:I[39756,[\"/blog/_next/static/chunks/ff1a16fafef87110.js\",\"/blog/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n4:I[37457,[\"/blog/_next/static/chunks/ff1a16fafef87110.js\",\"/blog/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n6:I[97367,[\"/blog/_next/static/chunks/ff1a16fafef87110.js\",\"/blog/_next/static/chunks/247eb132b7f7b574.js\"],\"OutletBoundary\"]\n7:\"$Sreact.suspense\"\n9:I[97367,[\"/blog/_next/static/chunks/ff1a16fafef87110.js\",\"/blog/_next/static/chunks/247eb132b7f7b574.js\"],\"ViewportBoundary\"]\nb:I[97367,[\"/blog/_next/static/chunks/ff1a16fafef87110.js\",\"/blog/_next/static/chunks/247eb132b7f7b574.js\"],\"MetadataBoundary\"]\nd:I[68027,[],\"default\"]\n:HL[\"/blog/_next/static/chunks/d335db6b3f1a2619.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"3vwnhP6rvgBy3ORnPg2gd\",\"c\":[\"\",\"posts\",\"mlir\",\"md5\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"posts\",{\"children\":[[\"slug\",\"mlir/md5\",\"c\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/blog/_next/static/chunks/d335db6b3f1a2619.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/blog/_next/static/chunks/796e69ae18b2784c.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"ko\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"main\",null,{\"children\":[[\"$\",\"header\",null,{\"style\":{\"display\":\"flex\",\"justifyContent\":\"space-between\",\"alignItems\":\"baseline\",\"gap\":12},\"children\":[[\"$\",\"h1\",null,{\"style\":{\"margin\":\"8px 0\"},\"children\":[\"$\",\"$L2\",null,{\"href\":\"/\",\"style\":{\"textDecoration\":\"none\"},\"children\":\"CPIST's blog\"}]}],[\"$\",\"nav\",null,{\"style\":{\"display\":\"flex\",\"gap\":12},\"children\":[\"$\",\"$L2\",null,{\"href\":\"/posts\",\"children\":\"Posts\"}]}]]}],[\"$\",\"hr\",null,{\"style\":{\"border\":0,\"borderTop\":\"1px solid #eee\",\"margin\":\"12px 0 24px\"}}],[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"footer\",null,{\"style\":{\"marginTop\":48,\"paddingTop\":16,\"borderTop\":\"1px solid #eee\",\"color\":\"#666\"},\"children\":[\"© \",2025,\" CPIST's blog\"]}]]}]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",null,[\"$\",\"$L6\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@8\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L9\",null,{\"children\":\"$@a\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@c\"}]}]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"article\",null,{\"children\":[[\"$\",\"div\",null,{\"style\":{\"color\":\"#666\",\"marginBottom\":6},\"children\":[\"$\",\"a\",null,{\"href\":\"/mlir\",\"style\":{\"textDecoration\":\"none\"},\"children\":[\"/\",\"mlir\"]}]}],[\"$\",\"h2\",null,{\"style\":{\"marginTop\":0},\"children\":\"MLIR Toy Tutorial Ch 5 에 대하여\"}],[\"$\",\"div\",null,{\"style\":{\"color\":\"#666\",\"marginBottom\":18},\"children\":\"2025-11-08\"}],[\"$\",\"p\",null,{\"style\":{\"color\":\"#333\"},\"children\":\"Partially lowering to lower-level dialects. We'll convert some of our high level language specific semantics towards a generic affine oriented dialect for optimization.\"}],[\"$\",\"hr\",null,{\"style\":{\"border\":0,\"borderTop\":\"1px solid #eee\",\"margin\":\"18px 0\"}}],[\"$\",\"div\",null,{\"className\":\"prose\",\"children\":[[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"왜 Affine 이라는게 필요한가?\\n다루고 있는 Toy는 수학계산하기 좋다. tensor 를 기반으로 하는 값 개념이다. (메모리에 없는)\"}],\"\\n\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"그런데 Affine은 반복문 \u0026 배열 최적화에 특화되어 있다.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"memref 기반이고 이말인 즉슨 실제 메모리 비퍼이다.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"따라서 계산-heavy 부분은 Affine 으로 / 출력(toy.print) 같은 건 \",[\"$\",\"code\",null,{\"children\":\"-\u003e\"}],\" 나중에 LLVM에서 처리하면 된다.\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"일단 Affine은 MLIR의 dialect 중 하나임. 근데 최적화를 위해 설계된 중간 단계 전용 dialect 임.\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"affine::AffineDialect\\n\\n기본적으로\\naffine.for\\naffine.if\\nafffine.load\\naffine.store\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"LLVM으로 바로 내려갈 수 없는 이유는\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"포인터 연산이 너무 자유롭고\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"루프 구조 분석이 어렵고\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"이게 같은 배열을 접근하는지 추적이 힘든 LLVM의 특징 때문임.\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Affine은 메모리 접근이 수식으로 딱 떨어지고, 컴파일러가 안전하다는 것을 보장하게 해줌.\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"// toy의 이 코드를\\n%y = toy.mul %x, %x\\n\\n// Affine 에서는\\naffine.for i ...\\n  affine.for j ...\\n    %v = affine.load %buf[i, j]\\n    %r = arith.mulf %v, %v\\n    affine.store %r, %out[i, j]\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이렇게 하여 연산 구조, 메모리 패턴, 반복 범위를 컴파일러 눈에 다 보이게 해줌.\\n루프와 메모리 접근을 수학적으로 깔끔하게 표현해서 컴파일러가 마음껏 최적화할 수 있게 만든 dialect 라는 것이다.\"}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"2\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"핵심 개념 1 : Dialect Conversion\\nMLIR에는 언어간 변환을 담당하는 DialectConversion Framework이 있다.\\n이를 쓰기 위해서는 3가지가 필요하다.\\n(1) Conversion Target\\n어디 까지 변환되면 성공인가? 즉 변환이 끝난 뒤 IR에 남아있는 op들이 이 집합(legal) 안에 있으면 성공이고, 하나라도 밖의 op가 있으면 실패이다.\"}],\"\\n\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"허용되는 것은 Affine, Arith, Func, memref\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"금지 되는 것은 Toy dialect 전체\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"예외는 toy.print는 부분 lowering으로 남겨둠. 여기서도 toy.print의 입력은 tensor는 안되고 memref 여야 한다.\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"(2) Rewrite Patterns\\nToy 연산을 Affine으로 어떻게 바꿀까?\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"toy.transpose\\n   ↓\\naffine.for + affine.load + affine.store\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"여기서 transpose는 중첩 loop 돌면서 인덱스를 뒤집어서 load / store 한다는 것을 알 수 있다.\\n좀더 자세히 살펴보자면 Toy는 아래와 같이 개념적 연산을 진행함. (행과 열을 바꾸는)\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"%out = toy.transpose %in : tensor\u003c2x3\u003e -\u003e tensor\u003c3x2\u003e\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"여기서는 내부적으로 loop도 없고, 메모리 접근도 없으며, 그냥 값이 바뀐다는 선언임.\\n그런데 Affine에서는 transpose 같은 고수준 연산이 없기 때문에 이를 직접 말해줘야 함.\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"affine.for i = 0 to 3 {\\n  affine.for j = 0 to 2 {\\n    ...\\n  }\\n}\\n\\n// transpose의 규칙\\nout[i][j] = in[j][i]\\n\\n// 그렇기에 아래처럼\\n%v = affine.load %input[j, i]\\naffine.store %v, %output[i, j]\\n\\n// 코드에서는 실제 아래처럼 쓰임\\nSmallVector\u003cValue, 2\u003e reverseIvs(llvm::reverse(loopIvs));\\nreturn affine::AffineLoadOp::create(builder, loc, input, reverseIvs);\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"인덱스를 뒤집는 다는건, loop 변수 순서는 그대로 쓰지만, load 할때만 index 순서를 거꾸로 쓴다는 것.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"(3) Type Converter\\n이 챕터에서는 안씀.\\n다만 tensor \",[\"$\",\"code\",null,{\"children\":\"-\u003e\"}],\" memref 개념은 중요하다는 것. (이건 OpConversionPattern 안에서 명시적으로 처리함.)\\ntensor \",[\"$\",\"code\",null,{\"children\":\"-\u003e\"}],\" memref는 새 버퍼를 만들고 값을 채우는 것.\"]}],\"\\n\",\"$Le\",\"\\n\",\"$Lf\",\"\\n\",\"$L10\",\"\\n\",\"$L11\",\"\\n\",\"$L12\",\"\\n\",\"$L13\",\"\\n\",\"$L14\",\"\\n\",\"$L15\",\"\\n\",\"$L16\",\"\\n\",\"$L17\",\"\\n\",\"$L18\",\"\\n\",\"$L19\",\"\\n\",\"$L1a\",\"\\n\",\"$L1b\"]}]]}]\n"])</script><script>self.__next_f.push([1,"e:[\"$\",\"ol\",null,{\"start\":\"3\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Partial Lowering (부분 변환)\\n모든 Toy 연산을 없애지 않고\"}],\"\\n\"]}]\nf:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"계산 \",[\"$\",\"code\",null,{\"children\":\"-\u003e\"}],\" Affine 변환\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"출력 (toy.print) 는 그대로 두었다. (위에서도 나왔던)\"}],\"\\n\"]}]\n10:[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"// 아직 안바뀐 Toy 연산이 있어도 괜찮다는 것\\napplyPartialConversion(...)\\n\"}]}]\n11:[\"$\",\"ol\",null,{\"start\":\"4\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"tensor \",[\"$\",\"code\",null,{\"children\":\"\u003c-\u003e\"}],\" memref를 어떻게 섞는가\\ntoy.print는 원래 tensor 만 받지만, 우리는 memref를 쓰고 있는 상황\"]}],\"\\n\"]}]\n12:[\"$\",\"p\",null,{\"children\":\"선택지는 3가지이다.\\n(1) memref 를 tensor로 복사하는 것은 느리고 최적화가 안되있음.\\n(2) 새로운 toy.print_memref를 만드는 것은 번거롭다.\\n(3) toy.print가 memref도 받게 하는 것이다. (이 챕터에서 사용한 방법)\"}]\n13:[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"// 현실적인 Toy dialect\\nAnyTypeOf\u003c[F64Tensor, F64MemRef]\u003e\\n\"}]}]\n14:[\"$\",\"ol\",null,{\"start\":\"5\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Toy 코드에서 Affine 으로 낮춘 예제 한개를 더 보자.\"}],\"\\n\"]}]\n15:[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"%2 = toy.transpose(%0)\\n%3 = toy.mul %2, %2\\ntoy.print %3\\n\"}]}]\n16:[\"$\",\"p\",null,{\"children\":\"이를 Affine으로 낮추면\"}]\n17:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"tensor는 memref.alloc 으로\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"연산은 affine.for 로\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"곱셈은 affine.load + arith.mulf 로\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"출력은 toy.print memref 로\"}],\"\\n\"]}]\n18:[\"$\",\"ol\",null,{\"start\":\"6\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"첫 변환 결과는 다소 애매하다.\\n불필요한 버퍼를 썼고, 같은 값을 여러번 load 했기 때문이다.\\n이를 해결하는 방법은 LoopFusion 과 AffineScalarReplacement 이다.\\n이 결과 루프가 합쳐지고, load 중복이 제거 되고, 메모리 사용이 감소된다.\"}],\"\\n\"]}]\n19:[\"$\",\"p\",null,{\"children\":\"=====================================================================\"}]\n1a:[\"$\",\"p\",null,{\"children\":\"정리해 보자면\"}]\n1b:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Partial lowering 의 개념과\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"tensor -\u003e memref의 전환 이유\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Affine dialect의 최적화 파워와\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"중간 단계 dialect의 가치에 대해 다루었다.\"}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"1c:I[27201,[\"/blog/_next/static/chunks/ff1a16fafef87110.js\",\"/blog/_next/static/chunks/247eb132b7f7b574.js\"],\"IconMark\"]\nc:[[\"$\",\"title\",\"0\",{\"children\":\"MLIR Toy Tutorial Ch 5 에 대하여 - CPIST's blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Partially lowering to lower-level dialects. We'll convert some of our high level language specific semantics towards a generic affine oriented dialect for optimization.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/blog/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"$L1c\",\"3\",{}]]\n8:null\n"])</script></body></html>