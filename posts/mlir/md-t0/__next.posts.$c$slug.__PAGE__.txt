1:"$Sreact.fragment"
16:I[97367,["/blog/_next/static/chunks/ff1a16fafef87110.js","/blog/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
17:"$Sreact.suspense"
0:{"buildId":"6tcypyG7B6pjiTJ69Ye7Q","rsc":["$","$1","c",{"children":[["$","article",null,{"children":[["$","div",null,{"style":{"color":"#666","marginBottom":6},"children":["$","a",null,{"href":"/mlir","style":{"textDecoration":"none"},"children":["/","mlir"]}]}],["$","h2",null,{"style":{"marginTop":0},"children":"MLIR Transform Tutorial Ch 0 에 대하여"}],["$","div",null,{"style":{"color":"#666","marginBottom":18},"children":"2025-11-16"}],["$","p",null,{"style":{"color":"#333"},"children":"A Primer on “Structured” Linalg Operations"}],["$","hr",null,{"style":{"border":0,"borderTop":"1px solid #eee","margin":"18px 0"}}],["$","div",null,{"className":"prose","children":[["$","ol",null,{"children":["\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"구조화된 (Structured) Linalg 연산에 대해 다루어 본다.\n기본적으로 MLIR의 Linalg는 \"계산의 모양 (구조)\" 을 오래 유지해서, 컴파일러가 똑똑하게 최적화(벡터화, 타일링, 퓨전 등) 할 수 있게 해주는 방식이다."}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"한번에 여러개 계산하기 (Uniform Elementwise)"}],"\n"]}],"\n"]}],"\n",["$","pre",null,{"children":["$","code",null,{"children":"%2 = arith.addf %0, %1 : f32\n"}]}],"\n",["$","p",null,{"children":"이런건 숫자 하나 + 숫자 하나인데"}],"\n",["$","pre",null,{"children":["$","code",null,{"children":"%2 = arith.addf %0, %1 : vector<8xf32>\n%2 = arith.addf %0, %1 : vector<8x4xf32>\n"}]}],"\n",["$","p",null,{"children":"MLIR에서는 위와 같이도 쓴다."}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"모든 원소에 똑같은 연산이라는 구조를 유지한다."}],"\n",["$","li",null,{"children":["컴파일러가","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"벡터 명령으로 바꾸거나"}],"\n",["$","li",null,{"children":"차원을 쪼개거나"}],"\n",["$","li",null,{"children":"add + mul 을 fused instruction 으로 합치기가 쉬워진다."}],"\n"]}],"\n"]}],"\n"]}],"\n",["$","ol",null,{"start":"3","children":["\n",["$","li",null,{"children":"벡터를 하나로 줄이기 (Reduction)"}],"\n"]}],"\n",["$","pre",null,{"children":["$","code",null,{"children":"// 벡터 전체를 더해서 스칼라 하나 만들기\n%1 = vector.reduction <add>, %0 : vector<8xf32> into f32\n"}]}],"\n",["$","p",null,{"children":"이건 사실 아래와 같다."}],"\n",["$","pre",null,{"children":["$","code",null,{"children":"sum = 0\nfor i in 0..7:\n  sum += v[i]\n"}]}],"\n",["$","p",null,{"children":"왜 굳이 이렇게 하는가?"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"어떤 하드웨어는 reduce 전용 명령어가 있다."}],"\n",["$","li",null,{"children":"어떤 경우엔 루프를 풀어서(unroll) 하는 게 더 빠를 수도 있음.\n이건 reduction 이라고 말해주면, 구현은 컴파일러가 선택함."}],"\n"]}],"\n",["$","ol",null,{"start":"4","children":["\n",["$","li",null,{"children":"곱하고 더하기 = contraction (Dot / Matmul 의 일반형)\nDot product 도 사실 이런 형태이다."}],"\n"]}],"\n",["$","pre",null,{"children":["$","code",null,{"children":"sum += a[i] * b[i]\n"}]}],"\n",["$","p",null,{"children":"MLIR에서는 아래와 같이 씀"}],"\n",["$","pre",null,{"children":["$","code",null,{"children":"vector.contract { ... } %a, %b, %init\n"}]}],"\n",["$","p",null,{"children":"여기서 중요한 개념이 2가지가 있음."}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":"indexing_maps"}],"\n"]}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"이 차원에서 어떤 인덱스를 쓰는지"}],"\n"]}],"\n",["$","ol",null,{"start":"2","children":["\n",["$","li",null,{"children":"iterator_types"}],"\n"]}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"\"parallel\" -> 그대로 유지"}],"\n",["$","li",null,{"children":"\"reduction\" -> 줄이는 차원"}],"\n"]}],"\n",["$","p",null,{"children":"그 결과"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"Dot product"}],"\n",["$","li",null,{"children":"Matrix x Matrix"}],"\n",["$","li",null,{"children":"Batch Matmul\n전부 같은 틀로 표현이 가능하게 된다.\n이건 matmul 이라는 것을 컴파일러가 바로 알아볼 수 있음"}],"\n"]}],"\n",["$","ol",null,{"start":"5","children":["\n",["$","li",null,{"children":"벡터 -> 메모리로 확장 (linalg.generic)\n레지스터 (vector) 말고 메모리 (memref / tensor) 에서 계산해보기"}],"\n"]}],"\n",["$","pre",null,{"children":["$","code",null,{"children":"linalg.generic {\n  indexing_maps = ...\n  iterator_types = ...\n} ins(...) outs(...) {\n  %x = mul\n  %y = add\n  linalg.yield %y\n}\n"}]}],"\n",["$","p",null,{"children":"내용은 생각보다 단순하다."}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"ins : 읽기 전용 입력"}],"\n",["$","li",null,{"children":"outs : 누적해서 쓰는 출력"}],"\n",["$","li",null,{"children":"region : 원소 하나에 대해 뭘 할지 적어둔 레시피\nfor 문 없이 for 문 의미를 표현함"}],"\n"]}],"\n",["$","ol",null,{"start":"6","children":["\n",["$","li",null,{"children":"암묵적인 Loop Fusion (임시 버퍼 제거)"}],"\n"]}],"\n",["$","pre",null,{"children":["$","code",null,{"children":"relu(x) = max(0, x)\n"}]}],"\n",["$","p",null,{"children":"보통은 비교 -> 선택 -> 임시버퍼인데\n이를 linalg.generic 안에 다 넣으면\ncmp -> select -> yield 가 된다."}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"임시 버퍼가 없고"}],"\n",["$","li",null,{"children":"루프는 딱 한번이고"}],"\n",["$","li",null,{"children":"나중에 벡터화 / 루프화 자유가 된다."}],"\n"]}],"\n","$L2","\n","$L3","\n","$L4","\n","$L5","\n","$L6","\n","$L7","\n","$L8","\n","$L9","\n","$La","\n","$Lb","\n","$Lc","\n","$Ld","\n","$Le","\n","$Lf","\n","$L10","\n","$L11","\n","$L12","\n","$L13","\n","$L14"]}]]}],null,"$L15"]}],"loading":null,"isPartial":false}
2:["$","p",null,{"children":"루프 안에서 할 일을 한번에 할 수 있다."}]
3:["$","ol",null,{"start":"7","children":["\n",["$","li",null,{"children":"Tensor 버전 : 더 똑똑한 추상화\nTensor는"}],"\n"]}]
4:["$","ul",null,{"children":["\n",["$","li",null,{"children":"읽기 전용"}],"\n",["$","li",null,{"children":"결과는 새 tensor로 생성"}],"\n",["$","li",null,{"children":"alias 걱정이 없다."}],"\n"]}]
5:["$","pre",null,{"children":["$","code",null,{"children":"%result = linalg.generic ... -> tensor<...>\n"}]}]
6:["$","p",null,{"children":"장점은"}]
7:["$","ul",null,{"children":["\n",["$","li",null,{"children":"의존성 분석이 쉽고"}],"\n",["$","li",null,{"children":"병렬화, 재배치, 퓨전에 최적화 되어 있음."}],"\n",["$","li",null,{"children":"컴파일러가 제일 좋아하는 형태이다."}],"\n"]}]
8:["$","ol",null,{"start":"8","children":["\n",["$","li",null,{"children":"타일링 = 암묵적 루프를 실제 루프로\n타일링이란?\n큰 계산을 여러개로"}],"\n"]}]
9:["$","pre",null,{"children":["$","code",null,{"children":"8x16 → (2x8) 타일 여러 개\n"}]}]
a:["$","p",null,{"children":"MLIR 에서는"}]
b:["$","ul",null,{"children":["\n",["$","li",null,{"children":"같은 linalg.generic"}],"\n",["$","li",null,{"children":"slice 만 바꿔서"}],"\n",["$","li",null,{"children":"바깥에 scf.forall 루프를 생성한다."}],"\n",["$","li",null,{"children":"즉 계산은 그대로인데 범위만 쪼개는 것임."}],"\n"]}]
c:["$","ol",null,{"start":"9","children":["\n",["$","li",null,{"children":["Producer / Consumer Fusion (Rematerialization)\n예를들어 matmul 결과 ",["$","code",null,{"children":"->"}]," elementwise 연산 일때"]}],"\n"]}]
d:["$","ul",null,{"children":["\n",["$","li",null,{"children":"이러면 전채 결과를 메모리에 쓸 필요가 없다."}],"\n"]}]
e:["$","p",null,{"children":"따라서"}]
f:["$","ul",null,{"children":["\n",["$","li",null,{"children":["타일 단위로","\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"matmul 부분 계산"}],"\n",["$","li",null,{"children":"바로 elementwise 연산"}],"\n",["$","li",null,{"children":"결과만 저장한다."}],"\n"]}],"\n"]}],"\n",["$","li",null,{"children":"메모리 트래픽이 감소되고"}],"\n",["$","li",null,{"children":"계산 조금 중보 될수도 있다. (rematerialization)\n메모리 vs 계산량 트레이드 오프를 컴파일러가 선택한다."}],"\n"]}]
10:["$","ol",null,{"start":"10","children":["\n",["$","li",null,{"children":"귀찮을 때는 이름 있는 연산을 쓰기"}],"\n"]}]
11:["$","pre",null,{"children":["$","code",null,{"children":"linalg.matmul ...\n\n위는 사실\n\nlinalg.generic { indexing_maps = ..., iterator_types = ... }\n의 축약형이다.\n"}]}]
12:["$","p",null,{"children":"읽기도 쉽고 의미도 명확하다."}]
13:["$","p",null,{"children":"====================================================================="}]
14:["$","p",null,{"children":"요약해 보자면 Structured Linalg는 의미를 오래 들고 있다가 하드웨어에 맞게 코드를 생성하는 방식이다.\n의미를 남겨두면 컴파일러가 최적화 할수 있게 한다."}]
15:["$","$L16",null,{"children":["$","$17",null,{"name":"Next.MetadataOutlet","children":"$@18"}]}]
18:null
