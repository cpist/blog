---
title: "MLIR Transform Tutorial Ch 0 에 대하여"
date: "2025-11-16"
summary: "A Primer on “Structured” Linalg Operations"
tags: ["mlir", "transform"]
draft: false
---

1) 구조화된 (Structured) Linalg 연산에 대해 다루어 본다.
기본적으로 MLIR의 Linalg는 "계산의 모양 (구조)" 을 오래 유지해서, 컴파일러가 똑똑하게 최적화(벡터화, 타일링, 퓨전 등) 할 수 있게 해주는 방식이다.

2) 한번에 여러개 계산하기 (Uniform Elementwise)

```
%2 = arith.addf %0, %1 : f32
```

이런건 숫자 하나 + 숫자 하나인데

```
%2 = arith.addf %0, %1 : vector<8xf32>
%2 = arith.addf %0, %1 : vector<8x4xf32>
```
MLIR에서는 위와 같이도 쓴다.
- 모든 원소에 똑같은 연산이라는 구조를 유지한다.
- 컴파일러가 
  - 벡터 명령으로 바꾸거나
  - 차원을 쪼개거나
  - add + mul 을 fused instruction 으로 합치기가 쉬워진다.

3) 벡터를 하나로 줄이기 (Reduction)

```
// 벡터 전체를 더해서 스칼라 하나 만들기
%1 = vector.reduction <add>, %0 : vector<8xf32> into f32
```

이건 사실 아래와 같다.
```
sum = 0
for i in 0..7:
  sum += v[i]
```

왜 굳이 이렇게 하는가?
- 어떤 하드웨어는 reduce 전용 명령어가 있다.
- 어떤 경우엔 루프를 풀어서(unroll) 하는 게 더 빠를 수도 있음.
이건 reduction 이라고 말해주면, 구현은 컴파일러가 선택함.

4) 곱하고 더하기 = contraction (Dot / Matmul 의 일반형)
Dot product 도 사실 이런 형태이다.
```
sum += a[i] * b[i]
```

MLIR에서는 아래와 같이 씀
```
vector.contract { ... } %a, %b, %init
```

여기서 중요한 개념이 2가지가 있음.
1. indexing_maps
- 이 차원에서 어떤 인덱스를 쓰는지
2. iterator_types
- "parallel" -> 그대로 유지
- "reduction" -> 줄이는 차원

그 결과
- Dot product
- Matrix x Matrix
- Batch Matmul
전부 같은 틀로 표현이 가능하게 된다.
이건 matmul 이라는 것을 컴파일러가 바로 알아볼 수 있음

5) 벡터 -> 메모리로 확장 (linalg.generic)
레지스터 (vector) 말고 메모리 (memref / tensor) 에서 계산해보기
```
linalg.generic {
  indexing_maps = ...
  iterator_types = ...
} ins(...) outs(...) {
  %x = mul
  %y = add
  linalg.yield %y
}
```

내용은 생각보다 단순하다.
- ins : 읽기 전용 입력
- outs : 누적해서 쓰는 출력
- region : 원소 하나에 대해 뭘 할지 적어둔 레시피
for 문 없이 for 문 의미를 표현함

6) 암묵적인 Loop Fusion (임시 버퍼 제거)
```
relu(x) = max(0, x)
```

보통은 비교 -> 선택 -> 임시버퍼인데
이를 linalg.generic 안에 다 넣으면
cmp -> select -> yield 가 된다.
- 임시 버퍼가 없고
- 루프는 딱 한번이고
- 나중에 벡터화 / 루프화 자유가 된다.

루프 안에서 할 일을 한번에 할 수 있다.

7) Tensor 버전 : 더 똑똑한 추상화
Tensor는
- 읽기 전용
- 결과는 새 tensor로 생성
- alias 걱정이 없다.
```
%result = linalg.generic ... -> tensor<...>
```

장점은
- 의존성 분석이 쉽고
- 병렬화, 재배치, 퓨전에 최적화 되어 있음.
- 컴파일러가 제일 좋아하는 형태이다.

8) 타일링 = 암묵적 루프를 실제 루프로
타일링이란?
큰 계산을 여러개로 
```
8x16 → (2x8) 타일 여러 개
```

MLIR 에서는 
- 같은 linalg.generic
- slice 만 바꿔서 
- 바깥에 scf.forall 루프를 생성한다.
- 즉 계산은 그대로인데 범위만 쪼개는 것임.

9) Producer / Consumer Fusion (Rematerialization)
예를들어 matmul 결과 `->` elementwise 연산 일때
- 이러면 전채 결과를 메모리에 쓸 필요가 없다.

따라서
- 타일 단위로
  - matmul 부분 계산
  - 바로 elementwise 연산
  - 결과만 저장한다.
- 메모리 트래픽이 감소되고
- 계산 조금 중보 될수도 있다. (rematerialization)
메모리 vs 계산량 트레이드 오프를 컴파일러가 선택한다.

10) 귀찮을 때는 이름 있는 연산을 쓰기

```
linalg.matmul ...

위는 사실

linalg.generic { indexing_maps = ..., iterator_types = ... }
의 축약형이다.
```

읽기도 쉽고 의미도 명확하다.

=====================================================================

요약해 보자면 Structured Linalg는 의미를 오래 들고 있다가 하드웨어에 맞게 코드를 생성하는 것이다.
의미를 남겨두면 컴파일러가 처리할수 있다.