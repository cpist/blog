---
title: "MLIR Toy Tutorial Ch 2 에 대하여"
date: "2025-10-26"
summary: "Traversing the AST to emit a dialect in MLIR, introducing base MLIR concepts. Here we show how to start attaching semantics to our custom operations in MLIR."
tags: ["mlir", "dialect"]
draft: false
---

1) MLIR은 왜 나오게 되었는가?
LLVM은 저레벨에 가까움
- 타입/명령어(인스트럭션) 세트가 꽤 고정되어 있음.
- 그래서 언어가 고수준이면 (텐서, 자동 미분, shape 추론 등)
     - 프런트엔드가 자기 혼자 분석/최적화/변환을 다 하다가
     - 마지막에 LLVM IR로 번역 진행
- 따라서 여러 언어가 비슷한 인프라를 매번 재구현 

MLIR은 이걸 해결하기 위해 나왔는데
MLIR은 이걸 고수준부터 저수준까지 여러 단계(IR 레벨)을 하나의 프레임워크에서 다루게 함.
이걸 가능하게 하는 핵심이 확장성(Extensibility) 이고, 이 방식이 Dialect이다.

2) Operation (그리고 빼놓을 수 없는 SSA)

MLIR에서 모든 건 Operation 임.
- LLVM의 instruction 같은 존재이기도 하고
     - 참고로 LLVM에서 instruction은 LLVM IR 안에서 '한 단계'의 계산/동작임. 즉 가장 기본 연산 단위
     - 산술/논리 연산 (add, mul, fadd, icmp), 메모리 접근 (alloca(스택 할당), load, store, getelementptr(주소 계산)), 제어 흐름 (br(분기), switch, ret), 함수 호출 (call, invoke)
     - LLVM IR은 SSA 기반이라, instruction이 값을 만들면 이름표가 붙음

여기서 SSA에 대해 좀 기나긴 설명을 진행해 보자.

```
%sum = add i32 %a, %b
```

    - add i32 %a, %b 가 instruction
    - %sum 은 그 instruction 이 만들어낸 SSA 값(result)
    - 참고로 SSA 는 Static Single Assignment로, 각 변수는 프로그램 전체에서 단 한 번만 값이 할당된다는 규칙을 가진 중간 표현 (IR) 방식임.

```
int x = 1;
x = x + 1;
x = x * 2;
```

사람은 이렇게 x가 여러번 쓰이는걸 이해하기 쉽지만, 컴파일러는 추적하기가 귀찮음.
SSA 스타일로 바뀌면 아래와 같아짐.

```
x1 = 1
x2 = x1 + 1
x3 = x2 * 2
```

이렇게 x1, x2, x3는 각각 한번만 정의되었음. 즉 변수가 재할당 되는게 아니라, 새 값을 만들 때마다 새 이름을 붙임.
LLVM IR 에서는 실제로 이런식임.

```
%x1 = add i32 0, 1
%x2 = add i32 %x1, 1
%x3 = mul i32 %x2, 2
```

SSA에서는 mutable 변수 개념이 사라지고
- 모든 값은 immutable
- 값의 흐름은 그래프 형태로 연결이 됨.
따라서 SSA는 보통 이렇게 생각을 함.
- 프로그램 = 값이 흘러가는 데이터 흐름 그래프

분기문이 있을경우에는

```
if (cond)
  x = 1;
else
  x = 2;
y = x + 3;
```

SSA는 아래와 같이 바꿈.

```
x1 = 1        ; then 블록
x2 = 2        ; else 블록
x3 = phi(x1, x2)
y  = x3 + 3
```

여기서 φ(phi) 함수 가 나오는데
이것의 의미는 어느 블록에서 왔느냐에 따라 값을 선택한다는 것.
실제 계산이 아니라 제어 흐름에 따른 값 선택 장치
LLVM IR 에서는 아래와 같이 생김

```
%x3 = phi i32 [ %x1, %then ], [ %x2, %else ]
```

이제 기나긴 SSA 설명을 끝내고 돌아와서...

- 함수, 모듈 같은 구조도 operation 으로 표현 가능함.

예를 들어 Toy의 전치 연산은

```
%t = "toy.transpose"(%tensor) {inplace = true} : (tensor<2x3xf64>) -> tensor<3x2xf64> loc("...":12:1)
```

- %t는 결과 SSA 값임
- "toy.transpose" : toy dialect의 transpose operation (dialect의 개념)
- (%tensor) : 입력 (operand)
- ` {inplace = true} ` : 속성(attribute) : 항상 상수인 메타데이터
- : (tensor `<2x3xf64>` ) -> tensor `<3x2xf64>` : 타입 (입력/출력)
- loc(...) : 소스코드 위치(디버깅/에러 추적용)
loc 이 중요한 이유는 LLVM 에서는 디버그 정보가 메타데이터라 날아갈수 있는데, MLIR 에서는 필수이기 떄문에 변환을 하더라도 이게 원래 코드 어디서 왔는지 추적이 가능함.

3) Dialect는 무엇일까?
언어 / 도메인의 개념을 MLIR에 꽂아 넣는 플러그인 묶음임.
- 고유 namespace를 갖고 (toy. 같은 접두사)
- 그 안에 operations, types, attributes 등을 등록함
- 그래서 MLIR이 그 의미를 알고 검증, 변환, 최적화를 할 수 있게 됨.

Toy는 그렇기 때문에 ToyDialect 를 정의하고

```
context.loadDialect<ToyDialect>();
```

이런 식으로 MLIRContext에 로딩해서 써먹을 수 있다.

4) 그런데 등록 안해도 MLIR은 돌아갈 수 있다. (Opaque API)
MLIR은 신기하게도 dialect 를 등록하지 않아도 "toy.transpose" 같은 텍스트 IR을 그냥 구조적으로만 파싱해서 round-trip(읽고->다시 출력) 가능.
단점은 의미를 모르니까 검증을 제대로 못하고, 말도 안되는 IR도 통과할 수 있다는 점이다.

```
%0 = "toy.print"() : () -> tensor<2x3xf64>
```

이런건 print가 operand도 없고, 리턴도 하면 안되는데 등록하면 MLIR은 그냥 모르는 op 니까 대충 넘어감.
따라서 무조건 dialect+operation 을 등록해서 의미를 알려줘야 한다.

5) toy.constant 같은 operation을 정식으로 정의하는 것
시작에 앞서 literal은 소스 코드에 '그 값 자체' 를 직접 써놓은 것을 말함. 계산 결과가 아니라 그냥 값 자체

```
[1, 2, 3]
[[1, 2, 3], [4, 5, 6]]
```

이렇게 계산이나 변수를 통해 오지 않은, 코드에 하드코딩된 텐서 값이 literal tensor
toy에서 literal tensor 를 SSA 값으로 만드는 op:

```
%4 = "toy.constant"() {value = dense<1.0> : tensor<2x3xf64>} : () -> tensor<2x3xf64>
```

입력 operand는 없는데, 대신 value 라는 attribute에 tensor 값이 들어있다. (dense elements)
결과로 tensor 하나를 뱉음.

6) Operation은 C++로 만들 수도 있고, TableGen(ODS) 로도 만들 수가 있음.
(1) C++ 로 직접 만들면
class ConstantOp : public mlir::Op `<...traits...> { ... }`
장점은 자유도가 있다는 점이고, 단점은 보일러플레이트(Boilerplate)가 많다는 점이다.
보일러플레이트는 매번 거의 똑같이 써야 하는 의미는 없고 형식만 중요한 코드임. (새로운 정보가 없다.)

(2) TableGen 으로 선언적으로 만들면
ODS (Operation Definition Specification) 을 통해 핵심 의미만 남고, 반복적이고 형식적인 코드는 자동 생성된다.

```
def ConstantOp : Toy_Op<"constant"> {
  let arguments = (ins F64ElementsAttr:$value);
  let results = (outs F64Tensor);
}
```

자동으로 
- 접근자(accessor) 가 생성되고 op.value() 같은
- trait이 일부 자동 추론이 되고 (operand는 0개이고, result는 1개인것 같은)
- 검증 로직도 상당 부분 자동 생성이 된다.
추가적으로
- summary/description 써서 문서 자동 생성도 가능하고
- hasVerifier = 1; 로 커스텀 검증도 붙일 수가 있음.
- builders 로 ConstantOp::build(...) 생성 규칙을 만들 수가 있음.
ODS는 "Operation 명세서를 쓰면 C++ 코드가 자동으로 생성되는 설계도 시스템인 셈."

7) Op vs Operation 
- Operation* : 모든 op를 담는 범용 박스 (opaque)
- ConstantOp 같은 Op 클래스 : 그 박스를 감싼 타입 안전한 래퍼 (like smart pointer)

```
ConstantOp op = llvm::dyn_cast<ConstantOp>(operation);
```

- mlir::Operation* = 모든 op의 공통 실체
- ConstantOp = 그 실체를 특정 op 타입으로 다루기 위한 타입 안전 래퍼
- dyn_cast `<ConstantOp>` (operation) = 이게 ConstantOp 맞으면 래퍼로 변환

즉 mlir::Operation* operation이 실제로 toy.constant 같은 ConstantOp에 해당하는 op라면, 그걸 ConstantOp 래퍼로 감싸서 돌려주거나, 아니면 실패(null 같은 값)로 돌려주라는 의미임.

8) Toy 코드가 MLIR에서는 어떻게 보이는 것인가?

```
var b<2,3> = [1,2,3,4,5,6];
```

MLIR에서는 이런 흐름으로
(1) 1D literal을 constant로 만들고 (tensor`<6xf64>`)
* 참고로 컴파일러에서는 constant랑 literal 이 다름. literal은 소스 코드에 쓰인 값이고, constant는 IR에서 상수로 표현 된 값임.
따라서 Literal -> (컴파일 과정) -> Constant
(2) reshape 로 tensor `<2x3xf64>` 로 바꾼다.

```
%2 = toy.constant dense<[...]> : tensor<6xf64>
%3 = toy.reshape(%2 : tensor<6xf64>) to tensor<2x3xf64>
```

즉, AST에서 "선언"으로 보였던 게 MLIR 에서는 constant + reshape 라는 명시적 op 시퀀스로 풀려나오는 것.

9) 왜 출력이 처음에는 지저분 하고 나중에는 깔끔해 질까?
처음에는 "generic assembly format" 이기 때문에

```
"toy.print"(%5) : (tensor<*xf64>) -> ()
```

쓸데 없는 괄호 / 타입 / 화살표가 붙어있음
이 op에 custom assembly format을 지정하면

```
toy.print %5 : tensor<*xf64>
```

사람이 읽기 좋게 줄일 수가 있음.
- C++ 에서 pint() / parse() 를 직접 구현하거나
- TableGen 에서 assemblyForamt = "..."; 로 선언적으로 지정 할 수 있음.

=====================================================================

긴 내용을 정리해 보자면
- MLIR은 확장 가능한 IR 프레임워크이고
- 이 확장의 단위는 Dialect 이다.
- Dialect 안에서 Operation을 정의해 의미 / 검증 / 빌더 / 출력 포맷을 제공한다.
- 등록 안 해도 "구조적으로" 는 다룰 수 있지만, 제대로 하려면 등록해야 한다.
- TOy AST -> Toy Dialect ops -> 더 낮은 레벨로 점점 lowering 이 가능해 진다.







