---
title: "MLIR TOSA Static Analysis"
date: "2026-01-07"
summary: "MLIR TOSA Static Analysis 방법론"
tags: ["mlir", "TOSA"]
draft: false
---

1) TOSA (Tensor Operator Set Architecture)란?
TOSA는 다양한 하드웨어 타겟(CPU, GPU, NPU)에서 추론을 수행하기 위해 설계된 표준 텐서 연산 집합임. 
Arm에서 처음 제안했으며, 현재는 MLIR의 핵심 Dialect로 포함되어 있음.

- 목적은 상위 프레임워크(TensorFlow, PyTorch)와 하위 코드 생성(LLVM IR, 하드웨어 특화 IR) 사이의 안정적인 교량(Stable Bridge) 역할 
- 특징은 아래와 같음
  - 하드웨어 독립적: 특정 가속기에 치우치지 않는 범용적인 연산을 정의
  - 양자화(Quantization) 최적화: 정수 연산 및 양자화 파라미터를 정교하게 다룸
  - 낮은 복잡도: 약 100개 미만의 기본 연산으로 구성되어 백엔드 구현 부담을 줄임

2) TOSA 정적 오류 분석 패스 작성법
MLIR에서 "정적 오류"를 찾는 방법은 크게 두 가지
- ODS 내장 Verifier: 각 Op의 타입, 랭크 등 구조적 정당성 체크
- Custom Analysis Pass: 특정 하드웨어 제약 조건 위반이나 데이터 흐름상의 논리 오류 검출

우리가 테스트 해볼것은 
TOSA 연산 중 특정 하드웨어가 지원하지 않는 설정(예: 커널 사이즈 제한)을 정적으로 찾아내는 패스

3) Pass 정의 (TableGen)
먼저 패스의 메타데이터를 정의
```
// MyTosaAnalysis.td
def MyTosaAnalysis : Pass<"my-tosa-analysis", "mlir::func::FuncOp"> {
  let summary = "TOSA 연산의 하드웨어 호환성을 정적으로 검토.";
  let description = [{
    이 패스는 TOSA Conv2D 연산의 커널 크기가 3x3보다 큰 경우 에러를 발생시킴.
  }];
  let constructor = "mlir::tosa::createMyTosaAnalysisPass()";
}
```

4) 분석 로직 구현 (C++)
walk 함수를 사용해 IR을 순회하며 검사
```
// MyTosaAnalysis.cpp
#include "mlir/Dialect/Tosa/IR/TosaOps.h"
#include "mlir/Dialect/Func/IR/FuncOps.h"  // func::FuncOp를 위해 필요
#include "mlir/IR/BuiltinTypes.h"         // ShapedType을 위해 필요
#include "mlir/Pass/Pass.h"

using namespace mlir;

namespace {
// 1. PassWrapper의 두 번째 인자는 실제 구현될 베이스 클래스임.
struct MyTosaAnalysisPass 
    : public PassWrapper<MyTosaAnalysisPass, OperationPass<func::FuncOp>> {
  
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(MyTosaAnalysisPass)

  // 최신 MLIR에서는 아래 함수들을 virtual로 인식시키기 위해 
  // StringRef를 반환하는 오버라이딩이 필요.
  StringRef getArgument() const final { return "my-tosa-analysis"; }
  StringRef getDescription() const final { return "TOSA Conv2D 커널 크기 정적 검증"; }

  void runOnOperation() override {
    // getOperation()은 이제 func::FuncOp를 반환.
    func::FuncOp func = getOperation();

    func.walk([&](tosa::Conv2DOp op) {
      // getType() 뒤에 바로 .cast를 쓰는 것보다 
      // llvm::dyn_cast 또는 llvm::cast를 사용하는 것이 더 안전함.
      auto weightType = llvm::dyn_cast<ShapedType>(op.getWeight().getType());
      if (!weightType) return;

      auto shape = weightType.getShape(); // [OC, H, W, IC]
      
      // TOSA Conv2D의 Weight는 보통 [OC, H, W, IC] 순서.
      if (shape.size() >= 3) {
        int64_t h = shape[1];
        int64_t w = shape[2];

        if (h > 3 || w > 3) {
          op.emitError() << "정적 검증 실패: 하드웨어 제약 조건 위반 (커널 " 
                         << h << "x" << w << " 미지원)";
          return signalPassFailure();
        }
      }
    });
  }
};
} // namespace

namespace mlir {
namespace tosa {
void registerMyTosaAnalysisPass() {
  PassRegistration<MyTosaAnalysisPass>();
}
} // namespace tosa
} // namespace mlir
```

* 여기서 walk 함수는 MLIR에서 IR 계층 구조를 자동으로 순회(Traversal) 하는 핵심.
MLIR은 Module -> Function -> Block -> Operation -> Region 의 계층적(Nested) 구조.
  - walk이 없다면, 특정 Op(예: tosa.conv2d)를 찾기 위해 4~5중 for문을 직접 작성해야 함
  - 재귀적 순회를 자동화 함: 최상위 Op(예: 함수)에서 호출하면 그 안에 포함된 모든 하위 Op들을 DFS 방식으로 탐색
  - 특정 타입을 필터링함: 템플릿 인자를 통해 내가 관심 있는 특정 Dialect의 Op만 골라서 콜백 함수를 실행할 수 있음
  - 보일러플레이트 제거: 반복문 관리, 반복자(Iterator) 무효화 등의 복잡한 처리를 내부적으로 해결

여기서 walk를 사용한건 함수 내부에 tosa.conv2d 가 어디에 있든 (루프 안이든, 조건문 안이든) 상관없이 모두 찾아내어 검증하기 위함.

* llvm::dyn_cast 에 대해서
내가 궁금했던 부분은 MLIR인데 왜 llvm 소스를 썼는가임.
MLIR은 LLVM의 인프라 위에 구축된 프로젝트임.
- 이말인 즉슨 LLVM이 제공하는 사용자 정의 RTTI(Run-Time Type Information) 메커니즘을 공유
- MLIR 소스 코드를 보면 mlir/Support/LLVM.h를 자주 포함
  - 즉, MLIR은 LLVM의 기초 유틸리티 모음인 LLVM Support Library에 깊게 의존
- llvm::dyn_cast, llvm::cast, llvm::isa 등은 특정 클래스에 종속된 함수가 아니라, 템플릿 기반의 범용 유틸리티
  - 이 템플릿들은 대상 객체가 특정한 규칙(인터페이스)만 지키고 있다면 어떤 타입이든 캐스팅할 수 있도록 설계

가벼운 RTTI (Hand-rolled RTTI)
- C++ 표준의 dynamic_cast는 실행 성능이 느리고 바이너리 사이즈를 키우는 경향이 있음
- LLVM/MLIR은 표준 RTTI 대신 classof라는 정적 메서드를 사용하는 커스텀 RTTI를 직접 구현해서 씀
- 설계 구조의 핵심 (classof): 모든 MLIR Operation(예: tosa::Conv2DOp)이나 Type은 내부에 classof라는 정적 함수를 가짐
```
// TableGen에 의해 자동 생성되는 코드의 개념적 모습
struct Conv2DOp : public Op<Conv2DOp, ...> {
  static bool classof(Operation *op) {
    // 이 Operation의 이름이 "tosa.conv2d"인지 확인
    return op->getName().getStringRef() == "tosa.conv2d";
  }
};
```
`llvm::dyn_cast<T>(obj)`를 호출하면, 템플릿 내부에서 T::classof(obj)를 호출
  - "이 객체가 정말 T 타입으로 변환 가능한가?"를 체크
  - 맞다면 포인터를 변환해주고, 틀리다면 nullptr을 반환

포인터 래퍼(Pointer Wrapper) 설계
  - tosa::Conv2DOp는 실제 거대한 객체가 아니라, Operation* 포인터 하나를 들고 있는 아주 가벼운 래퍼(Wrapper) 클래스
  - 구조적으로 tosa::Conv2DOp 객체를 복사해도 실제로는 포인터 하나만 복사됩니다. (값 복사가 아닌 참조 복사처럼 동작)
  - 유연성 측면에서 이러한 설계 덕분에 Operation*라는 범용 포인터를 하드웨어 제약 조건이 담긴 tosa::Conv2DOp라는 구체적인 클래스로 아주 가볍고 빠르게 재해석할 수 있음

Dialect 간의 확장성 (Extensibility)
  - MLIR은 수많은 Dialect(TOSA, Linalg, Affine 등)가 공존
    - 이들이 모두 dyn_cast를 쓸 수 있는 이유
  - 모든 연산은 결국 최상위 부모인 **mlir::Operation**으로 통하기 때문
  - 각 Dialect는 TableGen을 통해 자신만의 **Unique ID(또는 이름)**를 가짐
  - llvm::dyn_cast는 이 ID나 이름을 대조하여 캐스팅 여부를 판단

5) 실제 테스트 
1. 4)에 언급된 소스를 llvm-project/mlir/lib/Dialect/Tosa/Transforms/ 에 MyTOsaAnalysis.cpp 같은 파일로 저장하자.
2. mlir/lib/Dialect/Tosa/Transforms/CMakeLists.txt 를 열어서 add_mlir_dialect_library 부분에 MyTosaAnalysis.cpp를 추가하자
```
add_mlir_dialect_library(MLIRTosaTransforms
  TosaDecomposeConv2D.cpp
  TosaInferShapes.cpp
  MyTosaAnalysis.cpp  # <-- 추가
  ...
)
```
3. mlir/tools/mlir-opt/mlir-opt.cpp 에 
```
namespace tosa {
  void registerMyTosaAnalysisPass();
}
```
를 namespace mlir 안에 넣자.
그리고 main 함수에 아래 내용을 registerAllPasses(); 아래에 넣자. 
```
mlir::tosa::registerMyTosaAnalysisPass();
```
4. 이제 빌드를 다시 진행하자. 빌드 디렉토리로 가서 ninja mlir-opt 로 빌드할 수 있음.
5. 임의로 아래와 같은 테스트 파일을 만들자.
```
func.func @test_conv_too_large(%input: tensor<1x28x28x32xf32>, %weight: tensor<16x5x5x32xf32>, %bias: tensor<16xf32>) -> tensor<1x24x24x16xf32> {
  // 5x5 커널이므로 에러가 발생해야 함
  %0 = "tosa.conv2d"(%input, %weight, %bias) {
    dilation = [1, 1],
    pad = [0, 0, 0, 0],
    stride = [1, 1]
  } : (tensor<1x28x28x32xf32>, tensor<16x5x5x32xf32>, tensor<16xf32>) -> tensor<1x24x24x16xf32>
  return %0 : tensor<1x24x24x16xf32>
}
```
6. 아래와 같은 커맨드로 수행 가능
```
./bin/mlir-opt --my-tosa-analysis test_tosa.mlir
```
![TOSA 분석 결과](/blog/images/Capture-1.png)

=====================================================================

물론 이건 테스트를 위한 쉬운 방법
더 좋고 일반적인 방법에 대해서는 다른 포스트에서 논의해 보겠음.