---
title: "Random Forest"
date: "2026-01-19"
summary: "Random Forest 기법"
tags: ["etc", "kaggle"]
draft: false
---

1) Random Forest 기법이란
여러개의 Decision Tree를 만들고, 그 결과들을 투표 (Ensemble) 시켜서 결과를 내는 모델임. 
오버 피팅 (과적합) 에 강하기 때문에 기본 모델로 가장 선호됨.

2) max_depth=5 로 두면 Tree의 길이를 제한해서 너무 복잡해 지지 않게 관리할수 있음.
max_depth는 개별 Decision Tree가 질문을 최대 몇단계 까지 던질것인가를 결정하는 파라미터임.

3) 좀더 자세히 설명하자면 Random Forest는 앞서 말했듯 수많은 의사 결정 Tree의 집합체
max_depth는 각 Tree가 아래로 얼마나 깊게 내려갈 수 있는지를 제한함.

- 뿌리 노드(Root Node): 첫 번째 질문 (예: 성별이 여성인가?)
- 자식 노드(Child Node): 질문에 대한 답(Yes/No)으로 갈라진 다음 단계
- max_depth = 5: 뿌리부터 바닥(Leaf)까지 이 질문의 단계를 최대 5층까지만 쌓겠다는 뜻입니다.

4) 투표와 관련된 파라미터는 n_estimators임.

- n_estimators (투표단의 수): 나무를 몇 개 만들 것인가? (예: n_estimators=100이면 100개의 나무가 각각 결과를 내고 투표함)
- max_depth (개별 투표자의 지식 수준): 각 나무가 데이터를 얼마나 복잡하게 파고들 것인가?

5) 왜 깊이를 제한해야 할까?
엔지니어링 관점에서 max_depth 조절은 Bias-Variance Trade-off를 최적화하는 과정

- 너무 깊으면 (High Depth, 예: 20 이상): * 모델이 훈련 데이터의 아주 사소한 노이즈까지 다 외워버림
- 너무 얕으면 (Low Depth, 예: 1~2): * 질문을 충분히 던지지 못해 데이터의 패턴을 파악하지 못함.

타이타닉 데이터 같은 경우 max_depth = 5 정도면: * 타이타닉 같은 소규모 데이터셋에서 적당히 중요한 특징들(성별, 객실 등급, 나이 등)만 훑고 지나가게 하여 일반화 성능을 높이는 적절한 수치

6) 수학적, 구조적 관점에서 나무의 깊이가 $d$일 때, 이론적으로 최하단 노드(Leaf Node)의 개수는 최대 $2^d$개가 됨.

- 즉, max_depth = 5이면 한 나무가 데이터를 최대 32개($2^5$)의 영역으로 쪼개서 판단한다는 의미
- 만약 깊이 제한이 없다면, 데이터 한 개가 남을 때까지 무한히 쪼개려 할 것

7) 당연히 정형 (Tabular Data) 를 다룰때 많이 씀 (수치나 카테고리)
- 베이스라인 모델을 잡거나
- 어떤 데이터가 중요한지 알고 싶을때
- 데이터 양이 아주 많지 않을때 도 안정적임.
