---
title: "Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations"
date: "2026-01-04"
summary: "Structure of Triton"
tags: ["paper", "triton"]
draft: false
---
Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations (2019) 는 MAPL 워크숍에서 발표된 논문임.
Triton 의 구조에 대해 다루고 있음

1) Triton Architecture Overview
Triton의 아키텍처는 크게 3단계로 나뉜다.

1. Triton-C (Frontend)
    - Tile Semantics: ANSI C(CUDA-C) 문법을 따르지만, int tile[16, 16]과 같이 **Tile(다차원 배열)**을 일급 객체(First-class citizen)로 취급
    - Broadcasting: NumPy와 유사한 브로드캐스팅 규칙을 언어 차원에서 지원하여 차원이 다른 텐서 간의 연산을 직관적으로 표현
    - SPMD on Blocks: CUDA와 달리 커널이 Single-threaded로 작성되지만
        - 각 인스턴스가 자동으로 병렬화되어 Global Range(Grid)의 특정 타일을 처리
        - 개발자는 스레드 간 동기화(Shared memory sync)를 직접 신경 쓸 필요가 없음

2. Triton-IR (Middle-end)
    - LLVM-based: LLVM-IR과 구조가 유사하지만 타일 레벨의 데이터 흐름(Data-flow)과 제어 흐름(Control-flow) 분석을 위한 확장이 포함됨
    - Tile Instructions: reshape, broadcast, dot, trans 같은 타일 전용 명령어가 추가됨
    - Predication: 타일 내부의 개별 요소에 대한 분기 처리를 위해 Predicated SSA (PSSA) 형식을 사용하여 제어 흐름을 표현

3. Triton-JIT (Backend)
    - Triton-IR을 입력받아 최적화된 머신 코드(PTX/LLVM bitcode)를 생성
    - Auto-tuner가 내장되어 있어 타일 크기 등의 메타 파라미터를 자동으로 최적화

2) Key Compiler Optimizations
Triton-JIT의 핵심 최적화 패스(Pass)들은 다음과 같음.

1. Machine-Independent Passes
    - Prefetching: 루프 내에서 타일 레벨 메모리 연산으로 인한 지연(Latency)을 숨기고자 함
        - 컴파일러가 루프를 감지하고 적절한 프리패칭(Pre-fetching) 코드를 삽입
        - Peephole Optimization: 타일 대수(Algebra) 속성을 이용해 Trans(Trans(X)) == X와 같은 패턴을 감지하고 단순화

2. Machine-Dependent Passes (GPU Targeting)
    - Hierarchical Tiling (계층적 타일링)
        - 타일을 Micro-tile, Nano-tile로 분해하여 GPU의 메모리 계층 구조(DRAM `->` L2 `->` L1/Shared `->` Register)에 딱 맞게 매핑
        - Polyhedral 모델 없이도 중첩된 타일링 구성을 자동으로 열거하고 최적화 가능
    - Memory Coalescing (메모리 결합)
        - Triton-IR은 논리적으로 Single-threaded이지만
            - 백엔드에서 이를 병렬화할 때 인접한 스레드가 인접한 메모리 주소에 접근하도록 스레드 순서를 재배치
        - 이를 통해 DRAM 트랜잭션 효율을 극대화
    - Shared Memory Allocation (공유 메모리 할당)
        - dot 연산처럼 연산 강도(Arithmetic Intensity)가 높은 작업의 피연산자를 Shared Memory에 저장
        - 변수의 Live Range를 분석하여 선형 시간(Linear-time) 스토리지 할당 알고리즘을 사용해 최적의 위치를 결정
    - Automatic Barrier Insertion (자동 동기화)
        - RAW(Read-After-Write) 및 WAR(Write-After-Read) 해저드를 감지하기 위해 데이터 흐름 분석(Data-flow analysis)을 수행
        - 필요한 지점에 자동으로 Barrier를 삽입하여 프로그램의 정확성을 보장

3) Performance Benchmarks
    - Matrix Multiplication: DeepSpeech2, Transformer 등의 워크로드에서 cuBLAS와 대등한 성능을 보임
        - 또한 타 DSL(Halide, TVM, PlaidML 등) 대비 최대 2-3배 빠른 성능을 기록
    - Convolutions: cuDNN의 IMPLICIT_GEMM 알고리즘을 재구현했을 때 성능 저하가 없음
        - 특히 ResNet 일부 태스크에서는 cuDNN보다 뛰어난 성능을 보임
    - Shift-Convolutions: 기존에는 핸드 튜닝된 커널과 cuBLAS 호출을 섞어 써야 했던 Shift-Conv를 Triton-C로 하나의 융합된(Fused) 커널로 구현
        - Shift 연산 비용을 거의 완벽하게 숨기는 성능을 달성

4) 엔지니어로서의 포인트
- Tile Semantics & Broadcasting
    - 기존의 스칼라 기반 루프 최적화(Loop transformation) 접근법 대신, Tile 자체를 타입으로 정의하고 연산 단위로 삼는 것이 하드웨어(Tensor Core 등) 활용에 얼마나 유리한지를 확인
    - Broadcasting 규칙을 IR 레벨에서 지원함으로써 차원 불일치 문제를 우아하게 해결하고 벡터화(Vectorization) 기회를 명시적으로 드러냄
- IR Design: Predicated SSA
    - GPU와 같은 SIMT 구조를 컴파일할 때 가장 까다로운 것 중 하나가 Divergent Control Flow
    - Triton은 타일 내부의 제어 흐름을 분기(Branch)가 아닌 Predicated SSA 형식(psi 명령어 등)으로 처리
    - 벡터화된 실행 흐름을 유지하면서도 조건부 연산을 효율적으로 표현
    - 이는 마스킹(Masking)을 통한 벡터 연산 최적화의 핵심이자, 배울 부분
- Automatic Synchronization
    - CUDA 프로그래밍의 가장 큰 진입 장벽인 __syncthreads() 수동 관리를 컴파일러 패스로 해결
    - **데이터 흐름 분석(Liveness Analysis)**을 통해 공유 메모리 접근 간의 의존성을 파악하고 Barrier를 자동 삽입
        - 이건 고성능 병렬 컴파일러의 핵심적으로 다루어야 할 부분이라 할 수 있음
- Optimization Space Extraction
    - Auto-tuner가 단순히 미리 정의된 템플릿을 튜닝하는 것이 아니라, IR에서 직접 최적화 공간(타일 사이즈, 계층 구조 등)을 추출하여 탐색
        - 컴파일러 기반 오토튜닝의 이상적인 방향성을 보여줬다고도 할 수 있다.

===============================================

이 논문을 요약해 보자면 왜 Triton을 구현했고, 어떻게 구현했는가에 포커싱 되어 있음.
- 딥러닝 분야에서 새로운 아이디어를 검증하고 배포할 때, 효율적인 연산 커널(Compute Kernel)의 부재가 병목이 되는 경우가 많음
    - cuBLAS나 cuDNN 같은 벤더 라이브러리는 성능이 뛰어나지만 제한된 연산만 지원하며
    - TVM이나 PlaidML 같은 DSL은 유연하지만 벤더 라이브러리만큼의 성능을 내기 어려움
Triton은 이러한 문제를 해결하기 위해 제안된 언어이자 컴파일러이다.

- 여기서 핵심 아이디어는 "Tile(타일)" 개념을 중심으로 한 프로그래밍 추상화이다.
    - Triton은 파라메트릭 타일 변수(parametric tile variables)를 사용하는 C 기반 언어(Triton-C)와 LLVM 기반의 중간 표현(Triton-IR)을 활용
    - 텐서 프로그램을 효율적인 GPU 코드로 컴파일
    - 결과적으로 cuBLAS와 대등한 성능을 내면서도 Shift convolution 같은 새로운 연구 아이디어를 효율적으로 구현


